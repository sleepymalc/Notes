\lecture{19}{31 Oct.\ 11:00}{Make Multiplicative Weight Update Faster}
\[
	\begin{aligned}
		\max~ & c^{\top} x  \\
		      & Ax \leq b ; \\
		      & x \geq 0,
	\end{aligned}
\]
where \(A \in \mathbb{R} _{\geq 0}^{m \times n}\).

\section{Speed Up Multiplicative Weight Update}
\begin{algorithm}[H]\label{algo:MWU-discrete-linear}
	\DontPrintSemicolon{}
	\caption{Multiplicative Weight Update for Positive \hyperref[def:packing-LP]{Packing Linear Program}}
	\KwData{\(A\), \(c\), \(b\), \(\epsilon \)}
	\KwResult{A solution \(x_{\text{out} }\)}
	\BlankLine

	\(\eta \gets (\log m) / \epsilon \)\;
	\For(){\(i = 1, \dots , m\)}{
		\(w_i(0) \gets 1 / b_i\)\;
	}
	\(x(0) = 0\)\Comment*[r]{\(x \in \mathbb{R} ^n\)}
	\(t = 0\)\;
	\;
	\While(){\(t < 1\)}{
	\(j^{\ast} \gets \argmax_{j \in [n]} c_j / (\sum_{i=1}^{m} A_{ij} w_i)\)\;
	\(\delta \gets \epsilon / (\eta \max _{i \in [m]} A_{ij^{\ast} })\)\Comment*[r]{Max step size}
	\(\delta \gets \min (\delta , 1 - t)\)\Comment*[r]{Handle the last iteration}
	\For(){\(i = 1, \dots , m\)}{
		\(w_i(t+\delta ) \gets w_i(t) \cdot e^{\eta \delta A_{ij^{\ast} }}\)\;
	}
	\(x (t+\delta ) \gets x (t) + \delta \mathbbm{1}_{j^{\ast} }\)\;
	\(t \gets t + \delta \)\;
	}
	\Return{\(x(1)\)}\;
\end{algorithm}

Naively, each iteration requires \(O(N)\), hence with \autoref{thm:MWU-discrete-non-uniform}, it's \(O(N m \log m / \epsilon ^2)\).

Without loss of generality, we may assume that \(c_j = 1\) for all \(j\). Hence, solving \(j^{\ast} \) is equivalent to solving \(\min _{j \in [n]} \sum_{i=1}^{m} A_{ij^{\ast} } w_i\). Let \(\lambda _j \coloneqq \sum_{i=1}^{m} A_{ij} w_i\).

\begin{intuition}
	Instead of solving \(j^{\ast} \) exactly, we allow to return some coordinate such that the returned \(\lambda _j\) is not too far from the optimal value.
\end{intuition}

Specifically, consider divide values into \((1 + \epsilon )\)-buckets.

\subsection{Implicit Linear Program}
\[
	\begin{aligned}
		\max~ & \sum_{T \in \mathcal{T} _G} x_T                                 \\
		      & \sum_{T \ni e} x_T \leq c(e)    & \forall e \in E ;             \\
		      & x_T \geq 0                      & \forall T \in \mathcal{T} _G.
	\end{aligned}
\]

\begin{algorithm}[H]\label{algo:MWU-discrete-tree-packing}
	\DontPrintSemicolon{}
	\caption{Multiplicative Weight Update for Positive \hyperref[def:packing-LP]{Packing Linear Program}}
	\KwData{A graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{\geq 0}\)}
	\KwResult{A solution \(x_{\text{out} }\)}
	\BlankLine

	\(\eta \gets (\log m) / \epsilon \)\;
	\For(){\(e \in E\)}{
		\(w_e(0) \gets 1 / c(e)\)\;
	}
	\(x(0) = 0\)\Comment*[r]{\(x \in \mathbb{R} ^n\)}
	\(t = 0\)\;
	\;
	\While(){\(t < 1\)}{
	\(T ^{\ast} \gets \min _{T \in \mathcal{T} _{G}} \sum_{e \in T} w(e)\)\;
	\(\delta \gets \epsilon / (\eta \max _{e \in E} w(e))\)\Comment*[r]{Max step size}
	\(\delta \gets \min (\delta , 1 - t)\)\Comment*[r]{Handle the last iteration}
	\For(){\(e \in T^{\ast} \)}{
		\(w_e(t+\delta ) \gets w_e(t) \cdot e^{\eta \delta / c(e)}\)\;
	}
	\(x (t+\delta ) \gets x (t) + \delta \mathbbm{1}_{j^{\ast} }\)\;
	\(t \gets t + \delta \)\;
	}
	\Return{\(x(1)\)}\;
\end{algorithm}

\subsection{Sparsification}
Given a graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{\geq 0}\). The goal of the sparsification is to obtain a new graph \(H = (V, E_H )\) with edge capacity \(c_H \colon E_H \to \mathbb{R} _{\geq 0}\) such that \(H\) ``approximate'' \(G\) and \(\lvert H \rvert \) is small.

\begin{theorem}
	Given any graph \(G\) on \(n\) vertices and \(m\) edges and an \(\epsilon \in (0, 1)\). There exists a graph \(H = (V, E_{H})\) and \(c_H \colon E_H \to \mathbb{R} _{\geq 0}\) such that
	\begin{enumerate}[(i)]
		\item \(\lvert E_H \rvert = O(n \log n / \epsilon ^2)\);
		\item for all \(S \subseteq V\), \(c_G(\delta _G(S)) \approx (1 + \epsilon ) c_H(\delta _H(S))\);
		\item there is a randomized algorithm the constructs \(H\) in \(O(m \log ^2 n)\).
	\end{enumerate}
\end{theorem}
It's known that there is a fully dynamic data structure for maintaining \hyperref[prb:MST]{MST} such that each operation takes \(O(\log ^3 n)\).