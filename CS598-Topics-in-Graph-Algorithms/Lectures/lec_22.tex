\chapter{Blocking Flow and Push-Relabel}
\lecture{22}{19 Nov.\ 11:00}{Blocking Flow and Link-Cut Tree}
We have mentioned the \hyperref[prb:s-t-max-flow]{max-flow} problem multiple times throughout the course, which is used as a primitive for several problems. For example, from \autoref{thm:isolating-min-cut}, we know that solving \hyperref[prb:Steiner-min-cut]{Steiner min-cut} reduces to polynomial-logarithmically many \hyperref[prb:s-t-max-flow]{max-flot} computations via \hyperref[prb:isolating-cut]{isolating cut}. Hence, in this chapter, we present several classical \hyperref[prb:s-t-max-flow]{max-flow} algorithms which are not usually taught.

Notably, all the algorithms we will see are based on the \hyperref[def:augmenting-path]{augmenting path} approach, first introduced by Ford and Fulkerson~\cite{ford1956maximal}.

\section{Augmenting Path Framework}
In this section, we first introduce the \emph{augmenting path framework} formally, and briefly talk about a naive algorithm for solving \hyperref[prb:s-t-max-flow]{max-flow} in \(O(m^2 n)\) time~\cite{dinic1970algorithm,edmonds1972theoretical} (Dinitz includes additional techniques that reduce the running time to \(O(m n^2)\) as we will see later).

\subsection{Ford-Fulkerson Algorithm}
Consider a directed graph \(G = (V, E)\) with capacities \(c \colon E \to \mathbb{R} _{+}\). In the augmenting path framework, algorithms repeatedly find an \hyperref[def:augmenting-path]{augmenting path} (or a collection of them) in the \hyperref[def:residual-graph]{residual graph}:

\begin{definition}[Augmenting path]\label{def:augmenting-path}
	An \emph{augmenting path} is a simple path through the directed graph \(G = (V, E)\) using only edges with positive capacity from the source to the sink.
\end{definition}

\begin{definition}[Residual graph]\label{def:residual-graph}
	Let \(G = (V, E)\) be a directed graph with capacities \(c \colon E \to \mathbb{R} _{+}\) and a \hyperref[def:flow]{flow} \(f\). The \emph{residual graph} \(G_f = (V, E_f )\) with capacities \(c_f \colon E_f \to \mathbb{R} _{+}\) where \(c_f (u, v) = c(u, v) - f(u, v) + f(v, u)\) for all \(e = (u, v) \in E\).\footnote{We let \(E_f \coloneqq \{ e = (u, v) \in V \times V \mid c_f(e) > 0 \} \) for convenience.}
\end{definition}

\begin{figure}[H]
	\centering
	\incfig{residual-graph}
	\caption{Residual edge induced by \(f\) on \(e\).}
	\label{fig:residual-graph}
\end{figure}

We then augment, i.e., add, the \hyperref[def:flow]{flow} along this path with a value equal to the bottleneck of the augmenting path to the current flow. By repeated this until we cannot find \hyperref[def:augmenting-path]{augmenting path} anymore.

\begin{algorithm}[H]\label{algo:Ford-Fulkerson}
	\DontPrintSemicolon{}
	\caption{Ford-Fulkerson Algorithm~\cite{ford1956maximal}}
	\KwData{A connected directed graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \), source \(s\), sink \(t\)}
	\KwResult{\hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} \(f\)}
	\BlankLine
	\(f \gets 0\)\;
	\;
	\While(\label{algo:Ford-Fulkerson-augmenting-path}\Comment*[f]{Update \(G_f\) implicitly}){\(\exists \text{\(s\)-\(t\) \hyperref[def:augmenting-path]{augmenting path} } P \in G_f \)}{
		\(b \gets \min _{e \in P} c(e)\)\Comment*[r]{Bottleneck}
		\For(){\(e \in P\)}{
			\(f(e) \gets f(e) + b\)\;
		}
	}
	\Return{\(f\)}\;
\end{algorithm}

\subsection{Naive Algorithm}
There are several variants we can do when finding the \hyperref[def:augmenting-path]{augmenting paths} in \autoref{algo:Ford-Fulkerson-augmenting-path}. To be naive, one can literally run \autoref{algo:Ford-Fulkerson} without any care. This will work already, by recalling the classical proof of \hyperref[thm:max-flow-min-cut]{max-flow min-cut theorem}:

\begin{theorem}[Max-flow min-cut]\label{thm:max-flow-min-cut*}
	If there is no \hyperref[def:augmenting-path]{augmenting path} in the \hyperref[def:residual-graph]{residual graph} \(G_f\) for some \(s\)-\(t\) \hyperref[def:flow]{flow} \(f\), then \(f\) is the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow}.
\end{theorem}
\begin{proof}
	Suppose there is no \hyperref[def:augmenting-path]{augmenting path} in \(G_f\), i.e., there is no valid simple \(s\)-\(t\) path. Then, it's clear that there is an \(S\)-\(T\) cut in \(G_f\) where \(s \in S\) and \(t \in T = V \setminus S\), such that all edges from \(S\) to \(T\) are saturated, i.e., \(c_f(u, v) = 0\) for \(u \in S\) and \(v \in T\). Hence, we have \(f(u, v) = c(u, v)\).

	Furthermore, all edges from \(T\) to \(S\) have zero \hyperref[def:flow]{flow}, i.e., \(f(v, u) = 0\) for \(u \in S\) and \(v \in T\). To see this, suppose there is some \((v, u)\) such that it carries some non-zero \hyperref[def:flow]{flow} \(f(v, u)\). Then, there exists a backward edge from \(u\) to \(v\) in \(G_f\), and hence there is a path from \(s\) to \(u\) and to \(v\) in \(G_f\), a contradiction.

	Combining these facts, the capacity of the cut \((S, T)\) is equal to \(\lvert f \rvert \), and from the fact that any \hyperref[def:flow]{flow} has value less than the capacity of every possible cut, \((S, T)\) is the \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} that witness the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} as well.
\end{proof}

With \autoref{thm:max-flow-min-cut*}, we can prove the following.

\begin{theorem}\label{thm:Ford-Fulkerson}
	\autoref{algo:Ford-Fulkerson} computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with integral edge capacities in \(O(m \lvert f^{\ast} \rvert)\) time, where \(\lvert f^{\ast} \rvert \) is the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} value.
\end{theorem}
\begin{proof}
	The correctness is from \autoref{thm:max-flow-min-cut*}. For the runtime, since each \hyperref[def:augmenting-path]{augmenting path} computation can be easily done in \(O(m)\) time with BFS, and for each augmentation, the \hyperref[def:flow]{flow} value increased by at least \(1\).
\end{proof}

\begin{corollary}
	There exists an integral \hyperref[prb:s-t-max-flow]{max-flow} when the graph is with integral capacities.
\end{corollary}
\begin{proof}
	It is obvious from the proof of \autoref{thm:Ford-Fulkerson}.
\end{proof}

\begin{corollary}\label{col:Ford-Fulkerson}
	Let \(W = \max _{e \in E} c(e)\), then \autoref{algo:Ford-Fulkerson} actually runs in \(O(mn W)\).
\end{corollary}
\begin{proof}
	From \hyperref[thm:max-flow-min-cut]{max-flow min-cut theorem}, we know that \(\lvert f^{\ast} \rvert \) is equal to the \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} cost, which is less than \(c(\delta ^+(\{ s \} ))\) for example. Then since \(c(\delta ^+(\{ s \} )) \leq n C\), we have \(\lvert f^{\ast} \rvert \leq nC\), hence the algorithm runs in \(O(mn W)\).
\end{proof}

We see that \autoref{col:Ford-Fulkerson} proves that the naive implementation of \autoref{algo:Ford-Fulkerson} does not lead to a truly polynomial time algorithm since the running time depend linearly on \(W\).

\subsection{Maximum Bottleneck Capacity Augmenting Path}
To be a bit more careful, the next idea is to always choose an \hyperref[def:augmenting-path]{augmenting path} \(P\) that has the maximum bottleneck capacity \(\max _{e \in P} c_f(e)\) in \autoref{algo:Ford-Fulkerson-augmenting-path}. Such an \hyperref[def:augmenting-path]{augmenting path} can be found in \(O(m \log n)\) time via binary search over the capacity of the bottleneck edge, and, for each guess, check for the \(s\)-\(t\) path in \(G_f\) after all the edges with capacity less than the guess were removed.

\begin{note}
	By being (much) more sophisticated, one can get \(O(\min (m + n \log n, m \log ^{\ast} n))\) time.
\end{note}

To see this leads to an actual improvement, we want to know how much progress each such \hyperref[def:augmenting-path]{augmenting path} guarantees to make.

\begin{prev}
	The \hyperref[def:flow]{flow} decomposition bound tells us that any \hyperref[def:flow]{flow} can be decomposed into at most \(m\) \hyperref[def:flow]{flow} paths.
\end{prev}

\begin{theorem}\label{thm:Ford-Fulkerson-max-bottleneck}
	By choosing the maximum bottleneck capacity \hyperref[def:augmenting-path]{augmenting path} in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph \(G = (V, E)\) with integral edge capacities in \(O(m^2 \log n \log nW)\) time, where \(W = \max _{e \in E} c(e)\).
\end{theorem}
\begin{proof}
	If we apply the above observation to the maximum ``remaining'' \hyperref[def:flow]{flow}, i.e., the maximum \hyperref[def:flow]{flow} in the \hyperref[def:residual-graph]{residual graph} \(G_f\) together with an averaging argument, we can conclude that at least one of these paths carries at least \(1 / m\)-fraction of the remaining value of the \hyperref[def:flow]{flow}. Hence, each \hyperref[def:flow]{flow} augmentation reduces the remaining value of the \hyperref[def:flow]{flow} by a factor of \(1 - 1 / m\).

	After \(O(m \log \lvert f^{\ast} \rvert )\) augmentations, the remaining flow would be less than \(1\). Since we have integral capacities, the obtained solution has to be optimal. We conclude that the overall running time is \(O(m \log n \cdot m \log \lvert f^{\ast} \rvert ) = O(m^2 \log n \log nW)\).
\end{proof}

\autoref{thm:Ford-Fulkerson-max-bottleneck} proves that \autoref{algo:Ford-Fulkerson} with choosing maximum bottleneck capacity \hyperref[def:augmenting-path]{augmenting path} leads to a weakly polynomial time algorithm since the running time now only depend on \(\log W\), which is the same as the capacity representation. However, we can ask for more.

\subsection{Shortest Augmenting Path}
Unlike the maximum bottleneck approach, which depend on the value representation; instead, the next idea leads to an algorithm that runs in \(O(m^2 n)\)~\cite{dinic1970algorithm,edmonds1972theoretical} via a naive implementation. The key is to implement \autoref{algo:Ford-Fulkerson-augmenting-path} by choosing the shortest \hyperref[def:augmenting-path]{augmenting path} (shortest w.r.t.\ the number of edges). From now on, unless specified, the capacities are not necessarily integral.

\begin{prev}
	Maximum bottleneck capacity \hyperref[def:augmenting-path]{augmenting path} is ``primal greedy,'' i.e., it applies a greedy strategy in which we improve our current solution in each step and then lower bounded the progress made by each such step in terms of the value of the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow}.
\end{prev}

Therefore, as the value of the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} directly depends on the value of capacities, this kind of ``primal greedy'' approach is inherently incapable of providing a strongly polynomial bound. Hence, we need a different way to measure our progress towards optimality. To see how can we improve upon this observation, consider the following.

\begin{prev}
	The way we certified the optimality of our current \hyperref[def:flow]{flow} \(f\) was by looking whether \(s\) and \(t\) are connected in \(G_f\). If not, \(f\) was already a \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow}; otherwise, it was not optimal (and the \(s\)-\(t\) path enables us to improve it).
\end{prev}

The question then is, can we make this yes/no statement quantitative to also be able to differentiate between the \hyperref[def:flow]{flows} that are ``almost maximum'' and the ones that might be ``far'' from being maximum? To this end, consider the \(s\)-\(t\) distance \(d_f(s, t)\) in \(G_f\), where each edge with positive residual capacity has length one, and every edge with zero residual capacity has length \(+\infty \). The intuition of considering \(d_f(s, t)\) is the following.

\begin{intuition}
	Any \hyperref[def:flow]{flow} in \(G_f\) has a fixed total volume (\(\leq m\) for unit capacity graph). Hence, if \(s\) and \(t\) are far apart, then not much \hyperref[def:flow]{flow} can fit in \(G_f\), as each \hyperref[def:flow]{flow} path has to utilize a lot of volume.
\end{intuition}

Specifically, observe that if \(d_f(s, t) \geq n\), then \(s\) and \(t\) are disconnected in \(G_f\), meaning that \(f\) is already a \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow}. Hence, naturally, our new goal is to design an \hyperref[def:augmenting-path]{augmenting path} based algorithm that aims to increase the \(s\)-\(t\) distance \(d_f(s, t)\) in \(G_f\).

\begin{problem*}
	What are the best \hyperref[def:augmenting-path]{augmenting paths} to use if we are interested in increasing \(d_f(s, t)\)?
\end{problem*}
\begin{answer}
	Shortest \hyperref[def:augmenting-path]{augmenting paths} are the obstacles to \(d_f(s, t)\) being large. So, we simply try to destroy them by augmenting the \hyperref[def:flow]{flow} with it.
\end{answer}

We note that finding the shortest \hyperref[def:augmenting-path]{augmenting path} correspond to running BFS in \(G_f\). Hence, it only takes \(O(m)\) time, hence the only challenge is how to ensure that this augmentation does not introduce new shortest paths in \(G_f\).

\begin{lemma}\label{lma:shortest-augmenting-path-non-decreasing}
	Let \(d_f(s, v)\) and \(d_f^{\prime} (s, v)\) to be the distance from \(s\) to \(v \in V\) in \(G_f\) before and after augmenting the \hyperref[def:flow]{flow} along some shortest \hyperref[def:augmenting-path]{augmenting path} \(P\), respectively, then \(d_f(s, v) \leq d_f^{\prime} (s, v)\).
\end{lemma}
\begin{proof}
	Suppose the opposite, and let \(A \neq \varnothing \) to be the set of vertices \(v\) such that \(d_f(s, v) > d_f^{\prime} (s, v)\). Let \(v\in A\) be the one with the minimum \(d_f^{\prime} (s, v)\). Let \(P^{\prime} \) be the shortest \(s\)-\(v\) path in \(G_f\) \emph{after} the augmentation, and let \(u\) be the vertex preceding \(v\) on this path (since \(v \neq s\), such path and \(u\) exist). Hence, we have \(d_f^{\prime} (s, v) = d_f^{\prime} (s, u) + 1\). Moreover, we must have that \(d_f(s, u) \leq d_f^{\prime} (s, u)\) since otherwise, \(u \in A\) and \(d_f^{\prime} (s, u) < d_f^{\prime} (s, v)\), contradicting the minimality of \(v\).

	\begin{claim}
		The last edge of \(P^{\prime} \), i.e., \((u, v)\), has zero residual capacity before augmented by \(P\).
	\end{claim}
	\begin{explanation}
		Otherwise, we can reach \(v\) from \(u\) before augmented by \(P\), hence
		\[
			d_f(s, v)
			\leq d_f(s, u) + 1
			\leq d_f^{\prime} (s, u) + 1
			= d_f^{\prime} (s, v),
		\]
		contradicting to the fact that \(v \in A\).
	\end{explanation}

	Hence, the only way for \((u, v)\) to have non-zero residual capacity after augmented by \(P\) would be if the edge \((v, u)\) belongs to \(P\). Since \(P\) is the shortest path before the augmentation, i.e., \(d_f(s, u) = d_f(s, v) + 1\). This means
	\[
		d_f(s, v)
		= d_f(s, u) - 1
		\leq d_f^{\prime} (s, u) - 1
		= d_f^{\prime} (s, v) - 2
		\leq d_f^{\prime} (s, v),
	\]
	which again contradicts to the assumption that \(v \in A\).
\end{proof}

\begin{note}
	\autoref{lma:shortest-augmenting-path-non-decreasing} states that the distance from \(s\) doesn't decrease, not only for \(t\), but for every \(v\).
\end{note}

By symmetry, we can argue that the distance from any \(v\) to \(t\) is also non-decreasing. Hence, augmenting the \hyperref[def:flow]{flow} using shortest paths indeed does not make things worse. We can further show that we're indeed making progress.

\begin{lemma}\label{lma:shortest-augmenting-path-progress}
	At most \(mn / 2\) shortest path augmentations can be made before \(d_f(s, t) \geq n\).
\end{lemma}
\begin{proof}
	We first note that each augmentation saturates at least one bottlenecking edge \((u, v)\). For an already saturated edge, before it can be saturated again in some subsequent augmentation, we must have pushed some \hyperref[def:flow]{flow} via an \hyperref[def:augmenting-path]{augmenting path} that contained the opposite edge \((v, u)\).

	Let \(d(w)\) be the distance from \(s\) to \(w \in V\) in the \hyperref[def:residual-graph]{residual graph} just before the first saturation of \((u, v)\), and let \(d^{\prime} (w)\) be the corresponding distance just before the \hyperref[def:flow]{flow} is pushed along \((v, u)\) in some subsequent augmentation that makes \((u, v)\) has non-zero residual capacity again, as mentioned above. Since we always augment the shortest paths, \(d(v) = d(u) + 1\) and \(d^{\prime} (u) = d^{\prime} (v) + 1\).

	From \autoref{lma:shortest-augmenting-path-non-decreasing}, we know that \(d(w) \leq d^{\prime} (w)\) for any \(w \in V\).  Hence, we have
	\[
		d^{\prime} (u)
		= d^{\prime} (v) + 1
		\geq d(v) + 1
		= d(u) + 2.
	\]
	Therefore, the distance from \(s\) to \(u\) has to increase by at least \(2\) by the time the edge \((u, v)\) can again be saturated by some \hyperref[def:augmenting-path]{augmenting path}. We conclude that each edge \((u, v)\) can be saturated at most \(n / 2\) times before \(d_f(s, u) \geq n\), so, there is at most \(mn / 2\) saturations and thus augmentations possible before \(d_f(s, t) \geq n\).
\end{proof}

\begin{note}
	We have no way of lower bounding how much \hyperref[def:flow]{flow} a particular \hyperref[def:flow]{flow} augmentation pushed. We can only argue that overall the \(mn / 2\) augmentations we managed to push the whole \hyperref[prb:s-t-max-flow]{max-flow} value. This is an important feature of the so-called primal-dual algorithms.
\end{note}

Hence, we have the following.

\begin{theorem}[\cite{dinic1970algorithm,edmonds1972theoretical}]\label{thm:Ford-Fulkerson-shortest-path}
	By choosing the shortest \hyperref[def:augmenting-path]{augmenting path} (w.r.t.\ \(d_f(s, t)\)) in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with general capacities in \(O(m^2 n)\) time.
\end{theorem}
\begin{proof}
	From \autoref{lma:shortest-augmenting-path-progress}, we know that at most \(O(mn / 2)\) augmentations is needed. Since finding each shortest \hyperref[def:augmenting-path]{augmenting path} requires \(O(m)\), the total running time takes \(O(m^2 n)\).
\end{proof}

\section{Blocking Flow}
Dinitz then consider augmenting the so-called \hyperref[def:blocking-flow]{blocking flow} in \autoref{algo:Ford-Fulkerson-augmenting-path}, based on the analysis of the shortest \hyperref[def:augmenting-path]{augmenting path} approach in \autoref{thm:Ford-Fulkerson-shortest-path}. It turns out that this leads to a speedup of the running time from \(O(m^2 n)\) to \(O(mn^2)\)~\cite{karzanov1973finding,dinic1970algorithm,goldberg1998beyond}. The idea is not to be wasteful:

\begin{prev}
	Previously, we recompute the shortest \hyperref[def:augmenting-path]{augmenting path} using \(O(m)\) time for each augmentation. Each search for a path via BFS gives us the whole shortest path tree, but we're only using one path from it.
\end{prev}

The reason why this is wasteful is that augmenting along a single path can take \(m\) iterations before the current shortest \(s\)-\(t\) path distance in \(G_f\) increases by one. Instead of augmenting along a single path, we try to do this for a collection of paths.

\begin{intuition}
	If we find a flow \(g\) in \(G_f\) such that \(g\) \emph{blocks} all \(s\)-\(t\) shortest paths of length at most \(d\), then after adding \(g\) to \(f\) in the \hyperref[def:residual-graph]{residual graph}, the shortest path distance increases by one. This can happen at most \(n\) times, since the shortest path distance between \(s\) and \(t\) is at most \(n\).
\end{intuition}

This intuition leads to the so-called \hyperref[def:blocking-flow]{blocking flow}, defined as follows.

\begin{definition}[Blocking flow]\label{def:blocking-flow}
	An \(s\)-\(t\) \hyperref[def:flow]{flow} \(f\) is a \emph{blocking flow} if for every \(s\)-\(t\) path \(p\), at least one edge in \(p\) is saturated by \(f\).
\end{definition}

\begin{note}
	In other words, a \hyperref[def:blocking-flow]{blocking flow} is a maximal \hyperref[def:flow]{flow} in that one cannot add greedily add \hyperref[def:flow]{flow} to \(f\) in \(G\), which is different from a \hyperref[prb:s-t-max-flow]{max-flow}.
\end{note}

To find a \hyperref[def:blocking-flow]{blocking flow} in a general graph \(G\), we can do a simple greedy search, where in each iteration we find an \(s\)-\(t\) path and augment along the path to saturate one additional edge. The capacities along the path are reduced and those that saturated are not considered in future path selections.

\begin{note}
	We are not computing a \hyperref[def:residual-graph]{residual graph} in this process.
\end{note}

It's clear that the greedy algorithm will terminate in \(O(m)\) iterations, and a naive implementation takes \(O(m^2)\) time. We claim the following while refer the proof to \autoref{lma:blocking-flow-progress} for a special case.

\begin{claim}
	Suppose \(f\) is a \hyperref[def:blocking-flow]{blocking flow} in \(G\), then \(d_{G_f}(s, t) > d_{G}(s, t)\).
\end{claim}

The above basically just a restatement of the intuition we have. This leads to an \(O(m^2 n)\) algorithm, since we know that we only need to augment \(n\) times, where in each iteration, we find a \hyperref[def:blocking-flow]{blocking flow} \(g\) in \(G_f\) and augment along \(g\). We see that this algorithm's running time is the same as \autoref{thm:Ford-Fulkerson-shortest-path}.

\subsection{Blocking Flow in Layer Graph}
The key observation that leads to an improvement from \(O(m^2 n)\) to \(O(mn^2)\) is that instead of finding a \hyperref[def:blocking-flow]{blocking flow} in the entire graph \(G_f\), it suffices to find it only in the ``layer graph'' consisting of the ``forward edges'' in the BFS computation. We first formalize the notion of ``forward edge'' as follows.

\begin{definition}[Admissible]\label{def:admissible}
	Given a directed graph \(G = (V, E)\) and a source \(s \in V\), an edge \(e \in E\) is \emph{admissible} if it points away from \(s\), i.e., \(e\) is a part of some \(s\)-\(v\) shortest path for some \(v \in V\).
\end{definition}

We can also talk about the \hyperref[def:admissible]{admissible} graph, i.e., the graph \((V, E^{\prime} )\) where \(E^{\prime} \) is the set of all \hyperref[def:admissible]{admissible} edges.\footnote{Implicitly, we will discard edges (and nodes) with distance beyond \(d(s, t)\).} Meanwhile, the \hyperref[def:admissible]{admissible} path is a path in the \hyperref[def:admissible]{admissible} graph.

\begin{note}
	The \hyperref[def:admissible]{admissible} edges ``hop''\footnote{This is different from the previous notion of ``\hyperref[not:hop]{hop}'' for negative edges.} exactly one BFS layer, and all other edges either stay in the same layer or go back.
\end{note}

The whole reason why augmenting \hyperref[def:blocking-flow]{blocking flows} on the \hyperref[def:admissible]{admissible} graph works is because we can still guarantee that we're making progress:

\begin{lemma}\label{lma:blocking-flow-progress}
	Suppose \(g\) is a \hyperref[def:blocking-flow]{blocking flow} in the \hyperref[def:admissible]{admissible} graph of \(G_f\), then \(d_{f^{\prime} }(s, t) > d_f(s, t)\), where \(f^{\prime} = f + g\).
\end{lemma}
\begin{proof}
	Let \(f\) and \(f^{\prime} \) be the \hyperref[def:flow]{flow} before and after augmentation via the \hyperref[def:blocking-flow]{blocking flow} \(g\). Since every edge on a shortest \(s\)-\(t\) path in \(G_f\) has to ``hop'' exactly one BFS layer, hence it has to be \hyperref[def:admissible]{admissible}. Furthermore, augmentation does not create in \(G_{f^{\prime} }\) any edges that would be \hyperref[def:admissible]{admissible} in \(G_f\), i.e., no new arcs in \(G_{f^{\prime} }\) would ``hop'' a BFS layer in \(G_f\).

	After the augmentation, there is some \(s\)-\(t\) cut in \(G_f\) such that all its \hyperref[def:admissible]{admissible} edges are saturated. Hence, every \(s\)-\(t\) path in \(G_{f^{\prime} }\) now has to use at least one edge that would not be \hyperref[def:admissible]{admissible} in \(G_f\), so that edge would not hop a BFS layer in \(G_f\). But, every edge in \(G_{f^{\prime} }\) as well as \(G_f\) can hop at most one BFS layer in \(G_f\), so there is no way for an \(s\)-\(t\) path in \(G_{f^{\prime} }\) to make up for not hopping a \(G_f\) BFS layer at least once. All such paths had to have length larger than the \(s\)-\(t\) distance in \(G_f\), hence the \(s\)-\(t\) distance in the new graph had to increase by at least one.
\end{proof}

Hence, we can again conclude that after at most \(n\) \hyperref[def:blocking-flow]{blocking flow} computations, we will have an \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow}. But this time, the \hyperref[def:blocking-flow]{blocking flow} computations only need to be done on a smaller \hyperref[def:admissible]{admissible} graph. This is faster since computing \hyperref[def:blocking-flow]{blocking flow} in a layer DAG (e.g., the \hyperref[def:admissible]{admissible} graph) can be done faster than the naive greedy algorithm in a general graph by ``adaptive DFS search''.

\begin{intuition}
	Augmenting the \hyperref[def:flow]{flow} using an \hyperref[def:admissible]{admissible} path does not create new \hyperref[def:admissible]{admissible} edges in the \hyperref[def:residual-graph]{residual graph}. Hence, when we saturate an edge on an \hyperref[def:admissible]{admissible} path, we can just discard it, as the reverse arc is never \hyperref[def:admissible]{admissible}.
\end{intuition}

Next, we discuss how to do this type of adaptive DFS search formally.

\subsection{Unit Capacity Graph}
Let's first consider the case of unit capacity graph. In this case, observe that a \hyperref[def:blocking-flow]{blocking flow} in the \hyperref[def:admissible]{admissible} graph corresponds to a maximal collection of edge-disjoint \hyperref[def:admissible]{admissible} path. Since we're now finding a maximal set, greedy is usually the best strategy. Consider running a DFS starting at \(s\):
\begin{enumerate}
	\item\label{algo:unit-adaptive-DFS-advance} In each step, \emph{advance} along an unexplored outgoing \hyperref[def:admissible]{admissible} edge.
	\item\label{algo:unit-adaptive-DFS-block} If reach \(t\), retrace the path back to \(s\) and \emph{block} it by adding it to the \hyperref[def:blocking-flow]{blocking flow} and discarding all edges on this path.
	\item\label{algo:unit-adaptive-DFS-retreat} If reach a vertex \(v \neq t\) with no outgoing \hyperref[def:admissible]{admissible} edges, \emph{retreat} back along the edge we came from to \(v\) and discard it.
	\item Once there is no \hyperref[def:admissible]{admissible} edges leaving \(s\), return the \hyperref[def:blocking-flow]{blocking flow}.
\end{enumerate}

This seems much like just search for an \hyperref[def:augmenting-path]{augmenting path}, but actually this is not.

\begin{intuition}
	The key difference is that we can save information about which part of the graph we already explored, hence this is ``adaptive.''
\end{intuition}

Crucially, as we never add new \hyperref[def:admissible]{admissible} edges, once a vertex is a dead end, it stays that way. This is why it is fine for us to discard an edge upon retreat.

\begin{theorem}\label{thmj:Ford-Fulkerson-blocking-flow-unit}
	By choosing the \hyperref[def:blocking-flow]{blocking flow} in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with unit capacities in \(O(mn)\) time.
\end{theorem}
\begin{proof}
	With \autoref{lma:blocking-flow-progress}, we only need to prove that the above adaptive DFS search takes \(O(m)\) for finding a \hyperref[def:blocking-flow]{blocking flow} in the \hyperref[def:admissible]{admissible} graph. There are three types of operations:
	\begin{itemize}
		\item \hyperref[algo:unit-adaptive-DFS-retreat]{\emph{Retreat}}: There is at most \(m\) retreats, as we always discard the edge when we do that. Hence, the total cost is \(O(m)\).
		\item \hyperref[algo:unit-adaptive-DFS-advance]{\emph{Advance}}: Advances can be charged to the total cost of retreats and blocks corresponding to traversing back the edge.
		\item \hyperref[algo:unit-adaptive-DFS-block]{\emph{Block}}: Each blocking of a path \(P\) takes \(O(\lvert P \rvert )\) time, but also discards \(\lvert P \rvert \) edges. Hence, with amortization, it is \(O(1)\) per edge. The total time is then \(O(m)\).
	\end{itemize}
	Hence, the total cost is \(O(m)\), which proves that the total runtime is \(O(mn)\).
\end{proof}

However, this is just like our naive algorithm from \autoref{col:Ford-Fulkerson}, which takes \(O(mnW) = O(mn)\) as \(W = 1\) in this case. The upshot is that our analysis can be improved for \emph{simple graph}:

\begin{corollary}[\cite{even1975network}]\label{col:Ford-Fulkerson-blocking-flow-unit}
	\autoref{thmj:Ford-Fulkerson-blocking-flow-unit} can be improved to \(O(m \cdot \min (\sqrt{m} , n^{2 / 3}))\) for simple graph.
\end{corollary}
\begin{proof}
	We prove the result in two cases.

	\begin{claim}
		We can improve the bound to be \(O(m^{3 / 2})\).
	\end{claim}
	\begin{explanation}
		Suppose we already did \(k\) \hyperref[def:blocking-flow]{blocking flows}. Consider the \hyperref[prb:s-t-max-flow]{max-flow} in the \hyperref[def:residual-graph]{residual graph}: if we decompose it into paths, then the number of these paths will be exactly the value of the remaining \hyperref[def:flow]{flow}. Since we have done \(k\) \hyperref[def:blocking-flow]{blocking flows}, the \(s\)-\(t\) distance in the \hyperref[def:residual-graph]{residual graph} is greater than \(k\), hence, each of these \hyperref[def:flow]{flow} paths has length greater than \(k\).

		Since these \hyperref[def:flow]{flow} paths are edge-disjoint, with their total volume being \(m\), the number of these \hyperref[def:flow]{flow} paths is less than \(m / k\). Each \hyperref[def:blocking-flow]{blocking flow} increases the value of the \hyperref[def:flow]{flow} by at least one, as there always is at least one \hyperref[def:admissible]{admissible} path. Hence, \(m / k\) additional \hyperref[def:blocking-flow]{blocking flows}\footnote{Or even just \hyperref[def:augmenting-path]{augmenting paths} can do the job.} suffices. Combing the above, the total running time is then \(O(m (k + m / k))\) from \autoref{thmj:Ford-Fulkerson-blocking-flow-unit}, which is minimized when \(k = \sqrt{m} \), giving \(O(m^{3 / 2})\) as desired.
	\end{explanation}

	\begin{claim}
		We can improve the bound to be \(O(mn^{2 / 3})\).
	\end{claim}
	\begin{explanation}
		Suppose we already did \(k\) \hyperref[def:blocking-flow]{blocking flows}. It's clear that there are at most \(k / 2\) different layers in the BFS \hyperref[def:admissible]{admissible} graph with vertices greater than \(2n / k\) from a counting argument. Then by the pigeonhole principle, there are two consecutive layers such that both have less than \(2n / k\) vertices. There can be at most \(O(n^2 / k^2)\) edges between these two layers. Observe that these edges form an \(s\)-\(t\) cut, hence the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} value is \(O(n^2 / k^2)\).

		From a similar argument, we only need \(O(n^2 / k^2)\) additional \hyperref[def:blocking-flow]{blocking flows}, hence the total running time is \(O(m (k + n^2 / k^2))\) from \autoref{thmj:Ford-Fulkerson-blocking-flow-unit}, which is minimized when \(k = n^{2 / 3}\), giving \(O(mn^{2 / 3})\) as desired.
	\end{explanation}

	By combining the above two cases, we're done.
\end{proof}

\begin{remark}
	The \(O(m \sqrt{m} )\) bound extends to multi-graphs, while \(O(mn^{2 / 3})\) bound does not.
\end{remark}
\begin{explanation}
	This is clear from the counting argument for \(O(mn^{2 / 3})\), where we assume for two consecutive layers with each less than \(2n / k\) vertices, there are only \(O(n^2 / k^2)\) edges between them, which is not the case for multi-graphs.
\end{explanation}

\subsection{General Capacity Graph}
For graph with general capacities, as we promised at the beginning of this section, we can achieve \(O(mn^2)\) running time~\cite{karzanov1973finding,dinic1970algorithm,goldberg1998beyond}. To prove this, we look into what breaks for the adaptive DFS search for unit capacity case when we try the same analysis as in \autoref{thmj:Ford-Fulkerson-blocking-flow-unit} for general graphs.

From the previous adaptive DFS search algorithm, the basic idea of \hyperref[algo:unit-adaptive-DFS-advance]{advance}, \hyperref[algo:unit-adaptive-DFS-retreat]{retreat}, and \hyperref[algo:unit-adaptive-DFS-block]{block} are still valid. The key problem is that when augmenting, i.e., \hyperref[algo:unit-adaptive-DFS-block]{blocking}:

\begin{problem*}
	We might saturate only one bottlenecking edge on the \(s\)-\(t\) path we found!
\end{problem*}
\begin{answer}
	Simply retrace back to the tail of the farthest saturated edge and repeat.
\end{answer}

Specifically, consider the following modified version of the adaptive DFS search, starting at \(s\):
\begin{enumerate}
	\item\label{algo:general-adaptive-DFS-advance} In each step, \emph{advance} along an unexplored outgoing \hyperref[def:admissible]{admissible} edge.
	\item\label{algo:general-adaptive-DFS-block} If reach \(t\), \emph{block} the \(s\)-\(t\) path by adding it to the \hyperref[def:blocking-flow]{blocking flow} (with value to be the bottleneck) and discarding edges with \(0\) residual capacity on this path. Finally, retrace back to the head of the farthest saturated edge on this path.
	\item\label{algo:general-adaptive-DFS-retreat} If reach a vertex \(v \neq t\) with no outgoing \hyperref[def:admissible]{admissible} edges, \emph{retreat} back along the edge we came from to \(v\) and discard it.
	\item Once we retrace back to \(s\) and there is no \hyperref[def:admissible]{admissible} edges leaving \(s\), return the \hyperref[def:blocking-flow]{blocking flow}.
\end{enumerate}

\begin{theorem}\label{thm:Ford-Fulkerson-blocking-flow-general}
	By choosing the \hyperref[def:blocking-flow]{blocking flow} in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with general capacities in \(O(mn^2)\) time.
\end{theorem}
\begin{proof}
	In the new adaptive DFS search, every \hyperref[algo:unit-adaptive-DFS-advance]{advance} is still paid for by costs of corresponding \hyperref[algo:unit-adaptive-DFS-retreat]{retreat} or \hyperref[algo:unit-adaptive-DFS-block]{block}. In this case, all \hyperref[algo:general-adaptive-DFS-retreat]{retreats} still cost \(O(m)\) in total, and each \hyperref[algo:general-adaptive-DFS-block]{block} now costs \(O(n)\) as only one bottlenecking edge can be discarded per \hyperref[algo:general-adaptive-DFS-block]{block}. Therefore, the \hyperref[def:blocking-flow]{blocking flow} computation now takes \(O(mn)\) time, proving the result.
\end{proof}

\begin{intuition}
	Using \hyperref[def:blocking-flow]{blocking flows} enables us to charge \(m\) into \(n\) because of the resulting more efficient search for \hyperref[def:augmenting-path]{augmenting paths}.
\end{intuition}

In fact, we can make the above intuition stronger via an even more careful analysis.

\begin{corollary}\label{col:Ford-Fulkerson-blocking-flow-general}
	By choosing the \hyperref[def:blocking-flow]{blocking flow} in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with general capacities in \(O(mn + \lvert f^{\ast} \rvert n)\) time, where \(\lvert f^{\ast} \rvert \) is the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} value.
\end{corollary}
\begin{proof}
	Since each \hyperref[algo:general-adaptive-DFS-block]{block} corresponds to finding a new \hyperref[def:augmenting-path]{augmenting path}, hence, each \hyperref[algo:general-adaptive-DFS-block]{block} increases the value of the \hyperref[def:flow]{flow} by at least \(1\). This means that the total cost of \hyperref[algo:general-adaptive-DFS-block]{block} is only \(O(n \lvert f^{\ast} \rvert )\). Thus, the running time is actually \(O(mn + n \lvert f^{\ast} \rvert ) = O((m + \lvert f^{\ast} \rvert) n)\).
\end{proof}

In other words, the \hyperref[def:blocking-flow]{blocking flow} approach takes \(O(n)\) time ``per unit of flow routed,'' while the basic/naive \hyperref[def:augmenting-path]{augmenting path} approach took \(O(m)\) time (this is true even if capacities are not unit) as shown in \autoref{thm:Ford-Fulkerson-shortest-path}.

\subsection{Scaling Technique}
If we're dealing with integral capacities, we can utilize the idea of \textbf{scaling}, just like what we have seen in \autoref{algo:SSSP-scaling} for the \hyperref[prb:SSSP]{SSSP}. The general idea is still the same: apply the ``unit case'' algorithm to obtain a ``general numerical case'' algorithm. This time, consider the bit representation of the capacities. We observe that bits can correspond to unit case by looking at only the \(i^{\text{th} }\) bit at a time for every \(c(e)\)'s! To exploit this idea, consider the following:

\begin{intuition}
	Starting from an optimal solution to the rounded down instance (i.e., dropping some least significant bits for the capacities). One can repeatedly put back the next dropped bit, i.e., shifting/adding one bit to the right, and fix the solution along the way.
\end{intuition}

Such a shifting corresponds to a new capacity that is either doubled or doubled and plus \(1\). Hence, intuitively, the problem boils down to applying an algorithm that works well only for unit capacity case as every iteration we only need to deal with one unit of deviation in some sense.

\begin{note}
	One can think of scaling as a reverse process of rounding.
\end{note}

For convenience, we use the following notation to refer to \(i^{\text{th} }\) bit.

\begin{notation}
	Given \(a \in \mathbb{N} \), let \(a_i\) be the \(i^{\text{th} }\) most significant bit in \(a\)'s bit representation.
\end{notation}

Formally, the idea of scaling leads to a weakly polynomial algorithm.

\begin{theorem}\label{thm:Ford-Fulkerson-scaling}
	There exists a scaling-based algorithm that computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph \(G = (V, E)\) with integral capacities in \(O(mn \log W)\) time, where \(W = \max _{e \in E} c(e)\).
\end{theorem}
\begin{proof}
	We first describe the algorithm. In the first iteration, look at the most significant bit \(c^{(1)}(e) = c_1(e) \in \{ 0, 1 \} \), which corresponds to a unit capacity graph. We then obtain the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} \(f\) on the graph with capacity \(c^{(1)}\) via the unit capacity algorithm in \autoref{thmj:Ford-Fulkerson-blocking-flow-unit}, which takes \(O(mn)\) time. In the next iteration, we consider the new capacity \(c^{(2)}(e) \in \{ 0, 1, \dots , 2^2 \} \) to be the integer represented by the first two most significant bits of \(c(e)\), i.e., \(c^{(2)} (e) = 2 c^{(1)}(e) + c_2(e)\) for some \(c_2(e) \in \{ 0, 1 \} \). We also double \(f\) as \(f^{\prime} (e) = 2 f(e)\), which is clearly feasible for \(c^{(2)}\).

	Now, consider the corresponding \hyperref[def:residual-graph]{residual graph} \(G_{f^{\prime} }\). The crucial observation is the following.

	\begin{claim}
		There is a min-cut in \(G_{f^{\prime} }\) with residual capacity at most \(m\).
	\end{claim}
	\begin{explanation}
		Since our \hyperref[def:flow]{flow} was optimal before, there must exist an \(s\)-\(t\) cut with its residual capacity (w.r.t.\ \(f\)) be \(0\). Hence, after shifting a new bit and doubling the \hyperref[def:flow]{flow} to be \(f^{\prime} \), this cut has residual capacity being at most \(m\).
	\end{explanation}

	Hence, we see that after the bit shifting and doubling the current \hyperref[def:flow]{flow}, finding the new optimum boils down to solving the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} in a graph with \(\lvert f^{\ast} \rvert \leq m\). From \autoref{col:Ford-Fulkerson-blocking-flow-general}, we know that this takes \(O(mn)\) time.\footnote{Observe that after the shifting, \(G_{f^{\prime} }\) does not need to be unit capacity: we only have control on \(\lvert f^{\ast} \rvert \).} As there are only \(O(\log W)\) many shiftings required, the total running time of this algorithm is \(O(mn \log W)\).
\end{proof}

\begin{remark}
	The same idea with \autoref{thm:Ford-Fulkerson} improves \autoref{thm:Ford-Fulkerson-max-bottleneck} to \(O(m^2 \log W)\).
\end{remark}

\subsection{Data Structure for Blocking Flow}
So far, our best strongly polynomial time algorithm runs in \(O(mn^2)\) (\autoref{thm:Ford-Fulkerson-blocking-flow-general}), and weakly polynomial time algorithm runs in \(O(mn \log W)\) (\autoref{thm:Ford-Fulkerson-scaling}). A natural question is that whether we need to pay this extra factor of \(n\) for being strongly polynomial, or maybe there is a better way to implement \hyperref[def:blocking-flow]{blocking flows} in general graphs?

\begin{prev}
	In the adaptive DFS search, we repeatedly find \(s\)-\(t\) paths while discarding parts of the graph that we have finished searching. Suppose we find an \(s\)-\(t\) path \(P\). Then, we decrease the capacities along \(P\) as to saturate the bottleneck edge \(e\) along \(P\), removing \(e\) from the search. Then, we start the searching over from \(s\).
\end{prev}

The key bottleneck is that \hyperref[algo:general-adaptive-DFS-block]{blocking} in the adaptive DFS search takes \(\Theta (n)\) time but might only discard a single edge from the whole \hyperref[def:admissible]{admissible} path we found, and then we start the searching all over again from \(s\).

\begin{intuition}
	This is a waste of the two partial paths of \(p-e\), one from \(s\) and one to \(t\), respectively.
\end{intuition}

Hence, the question is that, as the pieces of this path that were not discarded are still useful, can we somehow take advantage of this fact and maintain these pieces for efficient access later? This is a data structure question, and fortunately, there is the so-called \hyperref[def:link-cut-tree]{link/cut tree}~\cite{sleator1985self} that supports all operations we need for implementing the adaptive DFS search!

Before we formally introduce the \hyperref[def:link-cut-tree]{link/cut tree}, we first need to define what an \hyperref[def:arborescence]{arborescence} is.

\begin{definition}[Arborescence]\label{def:arborescence}
	An \emph{arborescence} is a rooted directed tree with edges always directed towards the root.
\end{definition}

The \hyperref[def:link-cut-tree]{Link/cut tree} maintains a collection of \hyperref[def:arborescence]{arborescences} with several supported operations:

\begin{definition}[Link/cut tree]\label{def:link-cut-tree}
	The \emph{link/cut tree} data structure maintains a disjoint collection of \hyperref[def:arborescence]{arborescences}, which is modified via the following operations:
	\begin{itemize}
		\item \(\operatorname{\texttt{maketree}}(v) \): make a new \hyperref[def:arborescence]{arborescence} with only a root \(v\).
		\item \(\operatorname{\texttt{link}}(v, w) \): \(v\) is the root of an arborescence, and \(w\) is a vertex in a different \hyperref[def:arborescence]{arborescence} from \(v\), add a directed edge \((v, w)\), i.e., making \(v\) a child of \(w\).
		\item \(\operatorname{\texttt{cut}}(v) \): detach \(v\) from its \hyperref[def:arborescence]{arborescence} by deleting the edge toward \(v\)'s root, and make the sub-\hyperref[def:arborescence]{arborescence} rooted at \(v\) a new \hyperref[def:arborescence]{arborescence} in the collection.
	\end{itemize}
	For each vertex \(v\), the following queries are supported:
	\begin{itemize}
		\item \(\operatorname{\texttt{root}}(v) \): return the root of \(v\)'s arborescence.
		\item \(\operatorname{\texttt{min-capacity}}(v) \): return the minimum capacity edge in the path from \(v\) to its root.
		\item \(\operatorname{\texttt{add-capacity}}(v, c) \): add \(c\) to the capacity of every edge in the path from \(v\) to its root.
	\end{itemize}
\end{definition}

\begin{remark}
	In general, the \hyperref[def:link-cut-tree]{link/cut trees} allows for values along edges and vertices and efficient aggregate queries and updates along node-to-root paths in the arborescence. In \autoref{def:link-cut-tree}, we have defined two such operations (\(\operatorname{\texttt{min-capacity}}\) and \(\operatorname{\texttt{decrease-capacity}}\)) specifically for computing \hyperref[def:blocking-flow]{blocking flows} in \hyperref[def:residual-graph]{residual graphs}.
\end{remark}

It has been shown that the \hyperref[def:link-cut-tree]{link/cut tree} can be implemented efficiently.

\begin{theorem}[\cite{dominic1983data}]\label{thm:link-cut-tree}
	\hyperref[def:link-cut-tree]{Link/cut tree} can be maintained in amortized \(O(\log n)\) for each operation.
\end{theorem}
\begin{proof}[Proof intuition]
	To get a high level idea of the implementation, let us just consider the representation of an \hyperref[def:arborescence]{arborescence} when it is just a path.

	\begin{intuition}
		A path can be represented as a dynamic binary search tree (BST) of height \(O(\log n)\). Then all operations of a \hyperref[def:link-cut-tree]{link/cut tree} are trivial. For a general \hyperref[def:arborescence]{arborescence}, the \href{https://en.wikipedia.org/wiki/Heavy-light_decomposition}{heavy light decomposition}~\cite{dominic1983data} can essentially break it into a heavy path and some small things.
	\end{intuition}

	Specifically, consider maintaining an ordered list of vertices on path in a \href{https://en.wikipedia.org/wiki/Splay_tree}{splay tree} (but we could use any balanced BST). The key trick is that instead of storing the current residual capacity of each edge, store only the ``deltas'' \(\Delta \), i.e., their differences. This way, the true value of the residual capacity of an edge is obtained by summing all the \(\Delta \)'s on the path from that edge node to the root of the tree. Note that this representation is easy to maintain under rotations.

	To add a capacity of \(c\) on a path from some vertex \(v\) to the root of the path, splay successor of \(v\) to root, add \(c\) from the root of the left subtree. Similarly, one can maintain at each node the minimum capacity of its subtree (to help with \(\operatorname{min-capacity}(v) \)).
\end{proof}

We now formally describe how to use \hyperref[def:link-cut-tree]{link/cut tree} to speed up the adaptive DFS search for a general capacity graph, as described just above \autoref{thm:Ford-Fulkerson-blocking-flow-general}.

\begin{theorem}\label{thm:Ford-Fulkerson-link-cut-tree}
	By choosing the \hyperref[def:blocking-flow]{blocking flow} with \hyperref[def:link-cut-tree]{link/cut tree} in \autoref{algo:Ford-Fulkerson}, the algorithm computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with general capacities in \(O(mn \log n)\) time.
\end{theorem}
\begin{proof}
	We maintain a forest of \hyperref[def:arborescence]{arborescences} of ``\hyperref[algo:general-adaptive-DFS-block]{block}-able'' edges, i.e., \hyperref[def:admissible]{admissible} edges that are non-saturated. This means, we will discard parts of the graph that we have finished searching.

	Specifically, these \hyperref[def:arborescence]{arborescences} will always be subtrees of the \hyperref[def:residual-graph]{residual graph} such that \(s\) is always a leaf, and \(t\) is always a root (of some, potentially different, \hyperref[def:arborescence]{arborescences}). Moreover, the path from \(s\) to \(s\)'s root (in \(s\)'s \hyperref[def:arborescence]{arborescence}) represents a partial shortest path from \(s\) in the \hyperref[def:residual-graph]{residual graph}. The goal is to find a new \(s\)-\(t\) path to \hyperref[algo:general-adaptive-DFS-block]{block} by keep extending this path (at \(s\)'s root).
	\begin{itemize}
		\item Initially, all vertices are isolated by calling \(\operatorname{\texttt{maketree}}(v) \) for all \(v \in V\).
		\item In each iteration, start from the current vertex, i.e., \(s\)'s root \(r = \operatorname{\texttt{root}}(s) \).
		\item Unless \(r = t\), scan the unexamined outgoing \hyperref[def:admissible]{admissible} edges from \(r\) in the \hyperref[def:residual-graph]{residual graph}:
		      \begin{itemize}
			      \item If there is no edge at all, then there is no \(s\)-\(t\) path via \(r\). We \hyperref[algo:general-adaptive-DFS-retreat]{retreat} from \(r\):
			            \begin{itemize}
				            \item Delete \(r\) via calling \(\operatorname{\texttt{cut}} (e)\) for all \(e\) incident to \(r\). Discard \(r\) after this (which is doable since now \(r\) is just a singleton \hyperref[def:arborescence]{arborescence}).
				            \item Or if \(r = s\), we finish the search.
			            \end{itemize}
			      \item Otherwise, we find a directed \hyperref[def:admissible]{admissible} edge \((r, u)\) to \hyperref[algo:general-adaptive-DFS-advance]{advance}:
			            \begin{itemize}
				            \item Merge \(s\)'s \hyperref[def:arborescence]{arborescence} with \(u\)'s \hyperref[def:arborescence]{arborescence} via \(\operatorname{\texttt{link}}(r, u) \). This makes \(s\)'s \hyperref[def:arborescence]{arborescence} a sub-\hyperref[def:arborescence]{arborescence} of \(u\), and \(s\)'s new root becomes \(\operatorname{\texttt{root}}(u) \).
				            \item Repeat.
			            \end{itemize}
		      \end{itemize}
		\item If \(r = t\), then the \(s\)-\(r\) path \(P\) in \(s\)'s \hyperref[def:arborescence]{arborescence} is the desired \(s\)-\(t\) path. We \hyperref[algo:general-adaptive-DFS-block]{block} \(P\):
		      \begin{itemize}
			      \item Find the bottleneck capacity \(b\) on \(P\) via \(b = c(e)\) for some \(e = \operatorname{\texttt{min-capacity}}(s)\).
			      \item Decrease all edge capacities on \(P\) by \(b\) via calling \(\operatorname{\texttt{add-capacity}}(s, -b)\).
			      \item Cut all edges with capacity \(0\) now by calling \(\operatorname{\texttt{cut}} (e)\) for all \(e\) with \(c(e) = b\). These edges can be identified via calling \( \operatorname{\texttt{min-capacity}} (s)\) repeatedly and checking their capacity.
			      \item Repeat.
		      \end{itemize}
	\end{itemize}

	We continue the search until \(r = s\) and there are no edges leaving \(s\) left to explore. We claim that constructing a \hyperref[def:blocking-flow]{blocking flow} takes only constant number of \hyperref[def:link-cut-tree]{link/cut tree} operations.

	\begin{claim}
		Computing a \hyperref[def:blocking-flow]{blocking flow} takes a constant number of \hyperref[def:link-cut-tree]{link/cut tree} operations.
	\end{claim}
	\begin{explanation}
		Observe that the search does a constant number of operations per edge in the \hyperref[def:residual-graph]{residual graph} and per \hyperref[def:augmenting-path]{augmenting path} obtained by the search. For each edge \(e\), we \(\operatorname{\texttt{link}} (e)\) as it is searched, and \(\operatorname{\texttt{cut}} (e)\) as we either retrace from \(e\) or saturate \(e\).\footnote{When \(e\) is \(\operatorname{\texttt{cut}} (e)\) by saturation, it is also preceded by a \(\operatorname{\texttt{min-capacity}} (s)\) query that identifies it.} For each \hyperref[def:augmenting-path]{augmenting path}, we execute a constant number of operations (querying \(\operatorname{\texttt{min-capacity}} (s)\) or \(\operatorname{\texttt{add-capacity}} (s, -b)\)) to update the \hyperref[def:residual-graph]{residual graph}. Each \hyperref[def:augmenting-path]{augmenting path} saturates an edge that is then deleted from the \hyperref[def:residual-graph]{residual graph}, so there are at most \(m\) \hyperref[def:augmenting-path]{augmenting path}.
	\end{explanation}

	Hence, one can construct a \hyperref[def:blocking-flow]{blocking flow} in only \(O(m \log n)\) time, instead of \(O(mn)\) from \autoref{thm:Ford-Fulkerson-blocking-flow-general}. We conclude that the whole algorithm now takes only \(O(mn \log n)\) time.
\end{proof}

\begin{note}
	\autoref{thm:link-cut-tree} has a long line of history~\cite{shiloach1978n,galil1980eviog2v,sleator1981nm,sleator1981data,dominic1983data}.
\end{note}

\begin{corollary}\label{col:Ford-Fulkerson-link-cut-tree}
	There is an algorithm that computes the \hyperref[prb:s-t-max-flow]{\(s\)-\(t\) max-flow} on a directed graph with integral capacities in \(O(mn \log n^2 / m)\) time.
\end{corollary}
\begin{proof}
	With more care, the \(\log n\) factor in \autoref{thm:Ford-Fulkerson-link-cut-tree} can be improved to \(\log n^2 / m\)~\cite{goldberg1990finding}.
\end{proof}

Finally, for completeness, we summarized the algorithm described in \autoref{thm:Ford-Fulkerson-link-cut-tree} as follows.

\begin{algorithm}[H]\label{algo:Ford-Fulkerson-link-cut-tree}
	\DontPrintSemicolon{}
	\caption{\hyperref[algo:Ford-Fulkerson]{Ford-Fulkerson Algorithm} with \hyperref[def:link-cut-tree]{Link/Cut Tree}}
	\KwData{A connected directed graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \), source \(s\), sink \(t\)}
	\KwResult{A \hyperref[def:blocking-flow]{blocking flow} \(f\)}
	\SetKwFunction{Admissible}{\hyperref[def:admissible]{Admissible}}
	\SetKwFunction{LinkCutTree}{\hyperref[def:link-cut-tree]{Link/Cut Tree}}
	\SetKwFunction{Make}{maketree}
	\SetKwFunction{Link}{link}
	\SetKwFunction{Cut}{cut}
	\SetKwFunction{Root}{root}
	\SetKwFunction{MinCapacity}{min-capacity}
	\SetKwFunction{AddCapacity}{add-capacity}
	\BlankLine
	\(c^{\prime} \gets c\)\Comment*[r]{Record the original capacity}
	\(E^{\prime} \gets\)\Admissible{\(G\), \(c\), \(s\), \(t\)}\Comment*[r]{Set of \hyperref[def:admissible]{admissible} edges via DFS from \(s\) to \(t\)}
	\(T\gets\)\LinkCutTree{}\Comment*[r]{Initialize an empty \hyperref[def:link-cut-tree]{link/cut tree}}
	\;
	\For(){\(v \in V\)}{
		\(T\).\Make{\(v\)}\;
	}
	\;
	\While(){\(1 = 1\)}{
		\(r \gets T\).\Root{}\;
		\uIf(\Comment*[f]{Find an \(s\)-\(t\) path to \hyperref[algo:general-adaptive-DFS-block]{block}}){\(r = t\)}{
			\(e \gets T\).\MinCapacity{\(s\)}\;
			\(b \gets c(e)\)\;
			\(T\).\AddCapacity{\(s\), \(-b\)}\Comment*[r]{Assuming \(T\) and \(G\) shares \(c\)}
			\For(){\(e \gets T\).\MinCapacity{\(s\)}}{
				\If(){\(c(e) = 0\)}{
					\(T.\Cut{e}\)\;
					\(E^{\prime} \setminus \{ e \} \)\;
				}
			}
		}\Else{
			\uIf(\Comment*[f]{Retreat from \(r\)}){\(\nexists e = (r, v) \in E^{\prime} \)}{
				\If(\Comment*[f]{Delete saturated edges}){\(r = s\)}{
					\(f \gets c - c^{\prime} \)\label{algo:Ford-Fulkerson-link-cut-tree-compute-blocking-flow}\Comment*[r]{Compute \(f\)}
					\Return{\(f\)}\;
				}
				\For(){\(e = (v, r) \in E^{\prime} \)}{
					\(T\).\Cut{\(e\)}\;
				}
				\(T \gets T\setminus \{ r \} \)\;
			}\Else(\Comment*[f]{Find a directed \hyperref[def:admissible]{admissible} edge \((r, u)\) to \hyperref[algo:general-adaptive-DFS-advance]{advance}}){
				\(T\).\Link{\(r\), \(u\)}\;
			}
		}
	}
\end{algorithm}

\begin{remark}
	In \autoref{algo:Ford-Fulkerson-link-cut-tree-compute-blocking-flow}, as described in \autoref{thm:Ford-Fulkerson-link-cut-tree}, we're not actually augmenting the \(s\)-\(t\) path we found, we only \hyperref[algo:general-adaptive-DFS-block]{block} (i.e., add) them to the \hyperref[def:blocking-flow]{blocking flow} without introducing the residual edge, hence this step is necessary. One can also directly augment during the algorithm run.
\end{remark}