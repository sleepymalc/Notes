\lecture{4}{5 Sep.\ 11:00}{Steiner Min-Cut with Isolating Cuts}
\subsection{Steiner Min-Cut}
Consider the following problem that generalizes the \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} and \hyperref[prb:global-min-cut]{global min-cut}.

\begin{problem}[Steiner min-cut]\label{prb:Steiner-min-cut}
Given a graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \) and a set \(T \subseteq V\) of terminals, the \emph{Steiner min-cut} problem aims to find the min-cut \((S, V\setminus S)\) which separates some pair of terminals, i.e., \(S \cap T \neq \varnothing \) and \((V \setminus S) \cap T \neq \varnothing \).
\end{problem}

\begin{remark}
	\hyperref[prb:Steiner-min-cut]{Steiner min-cut} generalizes both \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} and \hyperref[prb:global-min-cut]{global min-cut}.
\end{remark}
\begin{explanation}
	\hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} corresponds to \(T = \{ s, t \} \), while \hyperref[prb:global-min-cut]{global min-cut} corresponds to \(T = V\).
\end{explanation}

A simple algorithm for the \hyperref[prb:Steiner-min-cut]{Steiner min-cut} is the same as the \hyperref[prb:global-min-cut]{global min-cut} by solving \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut}: for \(T = \{ t_1, \dots , t_k \} \), fix a terminal, say \(t_1\), then compute \hyperref[prb:s-t-min-cut]{\(t_1\)-\(t_i\) min-cut} for all \(i \geq 2\). This requires \(\lvert T \rvert - 1\) \hyperref[prb:s-t-max-flow]{max-flow} computations. In fact, this is the best known algorithm even for the \hyperref[prb:global-min-cut]{global min-cut} till~\cite{nagamochi1992computing}.

Quite recently, a simple yet striking approach that computes the \hyperref[prb:Steiner-min-cut]{Steiner min-cut} with high probability using only \(O(\log ^3 n)\) \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) cut} computations is developed~\cite{li2020deterministic}, which is based on \hyperref[prb:isolating-cut]{isolating cut}.

\subsubsection{Submodular Function}
The main interest here, i.e., solving \hyperref[prb:isolating-cut]{isolating cut}, will be essentially based on properties of \hyperref[def:symmetric]{symmetric} \hyperref[def:submodular]{submodular functions}. Although we can prove various properties by appealing to first principles, it's useful to see the proofs via \hyperref[def:submodular]{submodularity}. Here, we give some necessarily background.

\begin{definition*}
	Given a finite ground set \(V\), consider a real-valued set function \(f \colon 2^V \to \mathbb{R} \).
	\begin{definition}[Modular]\label{def:modular}
		The function \(f\) is \emph{modular} if for all \(A, B \subseteq V\),
		\[
			f(A) + f(B)
			= f(A \cap B) + f(A \cup B).
		\]
	\end{definition}
	\begin{definition}[Submodular]\label{def:submodular}
		The function \(f\) is \emph{submodular} if for all \(A, B \subseteq V\),
		\[
			f(A \cap B) + f(A \cup B)
			\leq f(A) + f(B).
		\]
	\end{definition}
	\begin{definition}[Supermodular]\label{def:supermodular}
		The function \(f\) is \emph{supermodular} if for all \(A, B \subseteq V\),
		\[
			f(A \cap B) + f(A \cup B)
			\geq f(A) + f(B).
		\]
	\end{definition}
	\begin{definition}[Posi-modular]\label{def:posi-modular}
		The function \(f\) is \emph{posi-modular} if for all \(A, B \subseteq V\),
		\[
			f(A - B) + f(B - A)
			\geq f(A) + f(B).
		\]
	\end{definition}
\end{definition*}

We note that perhaps a more common definition of \hyperref[def:submodular]{submodularity} is \emph{diminishing marginal utility}, i.e., if \(f(A + v) - f(A) \geq f(B + v) - f(B)\) for all \(A \subseteq B\). Here, we see some examples.

\begin{eg}[Modular function as weight function]
	\(f\) is \hyperref[def:modular]{modular} if and only if there exists some \(w\colon V \to \mathbb{R} \) such that \(f(A) = \sum_{v \in A} w(v) + c\) for some shift \(c\).
\end{eg}

\begin{eg}
	If \(f\) and \(g\) are \hyperref[def:submodular]{submodular}, then so is \(\alpha f + \beta g\) for some \(\alpha , \beta \geq 0\).
\end{eg}

One of the reason that \hyperref[def:submodular]{submodularity} is important for graphs is because of the following.

\begin{eg}[Cut]
	Given a graph \(G = (V, E)\), the cut size function \(\lvert \delta _G (\cdot) \rvert \colon 2^V \to \mathbb{R} _{+}\) is \hyperref[def:submodular]{submodular}.
\end{eg}
\begin{explanation}
	We simply note that for any \(A, B \subseteq V\),
	\[
		\lvert \delta _G (A) \rvert + \lvert \delta _G (B) \rvert
		= \lvert \delta _G (A \cap B) \rvert + \lvert \delta _G (A \cup B) \rvert + 2 \lvert E(A\setminus B, B\setminus A) \rvert
		\geq \lvert \delta _G (A \cap B) \rvert + \lvert \delta _G (A \cup B) \rvert ,
	\]
	where \(E(X, Y)\) is the set of edges crossing \(X\) and \(Y\) for some \(X, Y \subseteq V\).
\end{explanation}

The above argument extends naturally to non-negative capacitied graphs and directed graphs.

\begin{eg}
	For a directed graph, \(\lvert \delta ^{+} (\cdot) \rvert \) is \hyperref[def:submodular]{submodular} (so does \(\lvert \delta ^{-} (\cdot)\rvert \) by symmetry).
\end{eg}

We're also interested in the following property.

\begin{definition}[Symmetric]\label{def:symmetric}
	A set function is \emph{symmetric} if \(f(A) = f(V\setminus A)\) for all \(A \subseteq V\).
\end{definition}

Clearly, \(\lvert \delta _G(\cdot ) \rvert \) is \hyperref[def:symmetric]{symmetric}. However, for directed graph, this is not necessarily the case. Finally, we see that \hyperref[def:symmetric]{symmetric} \hyperref[def:submodular]{submodular} function satisfies another important property.

\begin{eg}
	A \hyperref[def:symmetric]{symmetric} \hyperref[def:submodular]{submodular} function is automatically \hyperref[def:posi-modular]{posi-modular}.
\end{eg}

Now, we discuss uncrossing, a common and powerful technique that is frequently used in working with \hyperref[def:submodular]{submodular functions}. We illustrate this in the context of \hyperref[prb:global-min-cut]{min-cuts}.

\begin{lemma}\label{lma:union-intersection-min-cut}
	Let \(G = (V, E)\) be a graph and \((A, V\setminus A)\), \((B, V\setminus B)\) be two \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cuts}. Then \((A \cap B, V\setminus (A \cap B))\) and \((A \cup B, V \setminus (A \cap B))\) are also \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cuts}.
\end{lemma}
\begin{proof}
	From \hyperref[def:submodular]{submodularity}, we have \(\lvert \delta (A) \rvert + \lvert \delta (B) \rvert \geq \lvert \delta (A \cap B) \rvert + \lvert \delta (A \cup B) \rvert \). However, as both \(A \cup B\) and \(A \cap B\) are themselves \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) cuts}, all terms need to be equal.
\end{proof}

\begin{corollary}\label{col:union-intersection-min-cut}
	For any graph \(G = (V, E)\), there is a unique (inclusion-wise) minimal \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut}.\footnote{While maybe not that useful, from the same logic, there is a unique maximal \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut}.}
\end{corollary}
\begin{proof}
	If there are two \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cuts} \(A, B\) that are both minimal and distinct, then \(A\setminus B \neq \varnothing \) and \(B \setminus A = \varnothing \) since otherwise one will be contained in the other, contradicting the minimality. From \autoref{lma:union-intersection-min-cut}, \(A \cap B\) is also a \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut} and \(A \cap B\) is a strict subset of \(A\) and \(B\), again contradicting minimality of \(A\) and \(B\).
\end{proof}

The above proof applies to directed graph as well since we only used \hyperref[def:submodular]{submodularity}.

\begin{remark}[Graphic matroid]
	A second aspect of \hyperref[def:submodular]{submodularity} in graphs comes via \emph{matroids}. We will not discuss it here but the rank function of a matroid is a special class of \hyperref[def:submodular]{submodular functions}; and in a formal sense, matroid rank functions are building blocks for all \hyperref[def:submodular]{submodular functions}. Given an undirected graph \(G = (V, E)\) there is a fundamental matroid associated with the edge set of \(G\) called the \emph{graphic matroid}.\footnote{There are other matroids that are also defined from graphs including the dual graphic matroid for instance.} Several properties of trees and forests can be better understood in the context of the graphic matroid including the \hyperref[thm:Tutte-Nash-Williams]{Tutte-Nash-Williams theorem}.
\end{remark}

\subsubsection{Isolating Cuts via Poly-Logarthmic Many Max-Flow Computations}
We can now formally introduce the \hyperref[prb:isolating-cut]{isolating cut} problem.

\begin{problem}[Isolating cut]\label{prb:isolating-cut}
Given a graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \) and a set \(T \subseteq V\) of terminals. The \emph{\(t_i\)-isolating cut} problem aims to find a cut \((S_i, V\setminus S_i)\) such that \(t_i \in S_i\) and \(t_j \notin S_i\) (i.e., \(t_j \in V \setminus S_i\)) for all \(j \neq i\), i.e., the cut isolates \(t_i\) from the rest of the terminals.
\end{problem}

The minimum capacity \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut} can be found by a single \hyperref[prb:s-t-max-flow]{max-flow} computation: by shrinking the terminals in \(T - t_i\) into a single vertex \(s\) and computing the \hyperref[prb:s-t-min-cut]{\(s\)-\(t_i\) min-cut}. Thus, naively, computing all \hyperref[prb:isolating-cut]{isolating cuts} require \(k\) \hyperref[prb:s-t-max-flow]{max-flow} computations. The upshot is that this can be done in only \(O(\log k)\) \hyperref[s-t-max-flow]{max-flow}. Before we describe the algorithm, we first note that from \hyperref[def:submodular]{submodularity}, we also have a similar structural result, just like \autoref{col:union-intersection-min-cut}.

\begin{lemma}\label{lma:unique-isolating-cut}
	There is a unique minimal \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut} \((S_i^{\ast} , V \setminus S_i^{\ast} )\) such that if \((S_i, V\setminus S_i)\) is any \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut}, then \(S_i^{\ast} \subseteq S_i\).
\end{lemma}

We now describe the algorithm for computing the \hyperref[prb:isolating-cut]{isolating cuts}. Basically, we consider \(h\) bi-partitions \((A_1, B_1), \dots , (A_h, B_h )\) with \(h = \lceil \log k \rceil \), and compute a cut separating each bi-partition. Then, we take the intersection among the resulting cut sets, which will be \hyperref[prb:isolating-cut]{isolating cuts} as we will see. Finally, with the structural property \autoref{lma:unique-isolating-cut}, we can then find the minimum \hyperref[prb:isolating-cut]{isolating cuts} from them.

\begin{algorithm}[H]\label{algo:isolating-cut}
	\DontPrintSemicolon{}
	\caption{\hyperref[prb:isolating-cut]{Isolating Cut}~\cite{li2020deterministic} (also developed independently in~\cite{abboud2021subcubic})}
	\KwData{A connected graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \), terminal \(T = \{ t_i \} _{i=1}^{k}\)}
	\KwResult{A set of \hyperref[prb:isolating-cut]{isolating cuts} \(\{ (S_i^{\ast} , V\setminus S_i^{\ast} )\}_{i=1}^{k} \) isolating \(t_i\)'s}
	\SetKwFunction{mincut}{\hyperref[prb:s-t-min-cut]{\(s\)-\(t\)-min-cut}}
	\BlankLine

	\For(\label{algo:isolating-cut-for-1}\Comment*[f]{\(\lceil \log k \rceil\) bi-partitions \((A_{\ell }, B_{\ell })\) of \(T\)}){\(\ell = 1, \dots , \lceil \log k \rceil\)}{
		\(A_{\ell } \gets \{ t_i \mid \text{binary representation of \(i\) has \(1\) in \(\ell^{\text{th}}\) bit} \} \)\;
		\(B_{\ell } \gets T \setminus A_{\ell } \)\;
		\((X_{\ell }, Y_{\ell } ) \gets\)\mincut{\(G\), \(c\), \(A_{\ell } \), \(B_{\ell } \)}\footnote{This can be done via shrinking \(A_{\ell } \) and \(B_{\ell } \) in to two separate nodes, and compute the \hyperref[prb:s-t-min-cut]{\(s\)-\(t\) min-cut}.}\label{algo:isolating-cut-bi-partition-cut}\Comment*[r]{\(Y_{\ell } = V\setminus X_{\ell } \) }
	}
	\For(){\(i = 1, \dots , k\)}{
	\(S_i \gets \bigcap_{\ell \colon t_i \in A_{\ell } } X_{\ell } \cap \bigcap_{\ell \colon t_i \in B_{\ell } } Y_{\ell } \)\label{algo:isolating-cut-U}\;
	\(H_i = (V_i, E_i)\gets\) shrinking \(V \setminus S_i\) to a single vertex \(s_i\)\label{algo:isolating-cut-H}\;
	\((S_i^{\ast} , V\setminus S_i^{\ast} )\gets\)\mincut{\(H_i\), \(c\), \(t_i\), \(s_i\)}\label{algo:isolating-cut-min-cut}\;
	}
	\Return{\(\{ (S_i^{\ast} , V\setminus S_i^{\ast} )\}_{i=1}^{k} \)}\;
\end{algorithm}

\begin{intuition}
	The following illustrates \autoref{algo:isolating-cut-bi-partition-cut}, where terminals are black vertices. \((A_{\ell } , B_{\ell } )\) is a bi-partition of \(T\), while \((X_{\ell } , Y_{\ell } )\) is a \hyperref[prb:s-t-min-cut]{min-cut} that separates \((A_{\ell }, B_{\ell } )\).
	\begin{figure}[H]
		\centering
		\incfig{isolating-cut-bipartition-cut}
	\end{figure}
	Additionally, \autoref{algo:isolating-cut-U} is created by considering the intersections of all \(X_{\ell } \) (or \(Y_{\ell } \)) that includes \(t_i\).
\end{intuition}

To see the correctness of the \autoref{algo:isolating-cut}, we want to say that \hyperref[prb:s-t-min-cut]{\(s_i\)-\(t_i\) min-cut} in \(H_i\) is exactly the minimum cost \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut} in \(G\). This is due to \autoref{lma:algo:isolating-cut}.

\begin{lemma}\label{lma:algo:isolating-cut}
	For each \(i\), \((S_i, V\setminus S_i)\) is a \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut}. Furthermore, \(S_i\)'s are pairwise disjoint.
\end{lemma}
\begin{proof}
	Firstly, \(t_i \in A_{\ell } \subseteq X_{\ell }\) or \(t_i \in B_{\ell } \subseteq Y_{\ell } \), implying \(t_i \in S_i\). Consider \(t_j\) with \(j \neq i\). As \(i \neq j\), there is some index \(\ell \) in the binary representation of \(i\) and \(j\) differ in the bit position. Suppose \(i\) has \(1\) in the \(\ell ^{\text{th} }\) position and \(j\) has \(0\), then \(t_i \in A_{\ell } \) and \(t_j \in B_{\ell } \), implying \(t_i \in X_{\ell } \) and \(t_j \notin X_{\ell } \) as \(t_j \in B_{\ell } \subseteq Y_{\ell } \) and \(Y_{\ell } \cap X_{\ell } = \varnothing \). This means \(t_j \notin S_i\).

	We now prove that \(S_i \cap S_j = \varnothing \) for all \(i \neq j\). Firstly, there exists some \(\ell \) such that \(t_i \in A_{\ell } \) and \(t_j \in B_{\ell } \) (or \(t_i \in B_{\ell } \) and \(t_j \in A_{\ell } \)). Suppose \(v \in X_{\ell } \), then \(v\) can't be in \(S_j \subseteq Y_{\ell } \) and if \(v \in Y_{\ell } \), then \(v\) can't be in \(S_i \subseteq X_{\ell } \), hence \(v\) can't be in both \(S_i\) and \(S_j\).
\end{proof}

\autoref{lma:algo:isolating-cut} gives the following picture, where each \(t_i\) lives in exactly one \(S_i\).

\begin{figure}[H]
	\centering
	\incfig{isolating-cut-unique-disjoint}
\end{figure}

Hence, for each \(i\), we have a \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut} \((S_i, V\setminus S_i)\). Now, \autoref{lma:unique-isolating-cut} states that there is a \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut} \((S_i^{\ast} , V\setminus S_i^{\ast} )\) where \(S_i^{\ast}\) is a subset of any \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut}, it doesn't say it will be a subset of \(S_i\) in particular, as \((S_i, V\setminus S_i)\) is only a \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut}. However, we do not lose anything:

\begin{lemma}\label{lma:unique-isolating-min-cut}
	The minimal \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut} \((S_i^{\ast} , V \setminus S_i^{\ast} )\) is in \((S_i, V\setminus S_i)\), i.e., \(S_i^{\ast} \subseteq S_i\).
\end{lemma}
\begin{proof}
	It suffices to prove that if \(t_i \in A_{\ell } \) then \(S_i^{\ast} \subseteq X_{\ell } \). Assume not, then \(S_i^{\ast} \cap (V\setminus X_{\ell } ) \neq \varnothing \). But since \(S_i^{\ast} \cap X_{\ell } \) is a \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut}, while \(S_i^{\ast} \) is the minimal \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut}, \(\lvert \delta (S_i^{\ast} \cap X_{\ell } ) \rvert > \lvert \delta (S_i^{\ast} ) \rvert \).

	Moreover, it's trivial to see that \(S_i^{\ast} \cup X_{\ell } \) is a \(A_{\ell } \)-\(B_{\ell } \) cut (not necessarily minimum, just a cut), hence we also have \(\lvert \delta (S_i^{\ast} \cup X_{\ell } ) \rvert \geq \lvert \delta (X_{\ell } ) \rvert \). From \hyperref[def:submodular]{submodularity} of \(\lvert \delta (\cdot) \rvert \), we have
	\[
		\lvert \delta (S_i^{\ast} ) \rvert + \lvert \delta (X_{\ell } ) \rvert
		\geq \lvert \delta (S_i^{\ast} \cap X_{\ell } ) \rvert + \lvert \delta (S_i^{\ast} \cup X_{\ell } ) \rvert,
	\]
	which is a contradiction.
\end{proof}

With all the lemmas, it's now easy to see that \autoref{algo:isolating-cut} is at least correct. Firstly, from \autoref{lma:unique-isolating-min-cut}, we know that the optimal \hyperref[prb:isolating-cut]{\(t_i\)-isolating min-cut} \(S_i^{\ast} \) is a subset of \(S_i\) (here, \(S_i^{\ast} \) is not necessary the one found by \autoref{algo:isolating-cut}, we're trying to argue this). As \(S_i\)'s are disjoint from \autoref{lma:algo:isolating-cut}, each terminal \(t_i\) lives in exactly one \(S_i\), hence computing \hyperref[prb:s-t-min-cut]{\(s_i\)-\(t_i\) min-cut} will indeed recover \(S_i^{\ast} \).

\begin{intuition}
	When we contract \(V \setminus S_i\), we do not lose the optimal \hyperref[prb:isolating-cut]{isolating cut} \(S_i^{\ast} \).
\end{intuition}

\begin{theorem}[\cite{li2020deterministic}]\label{thm:isolating-min-cut}
	\autoref{algo:isolating-cut} is a deterministic algorithm that given \(G = (V, E)\) and a terminal set \(T \subseteq V\) with \(\lvert T \rvert = k\), computes all the \hyperref[prb:isolating-cut]{isolating cuts} using \(O(\log k)\) \hyperref[prb:s-t-max-flow]{max-flow} computations on graphs with \(\lvert V \rvert \) vertices and \(\lvert E \rvert \) edges each.
\end{theorem}
\begin{proof}
	We analyze the runtime. It's easy to see that \autoref{algo:isolating-cut-for-1} requires \(O(\log k)\) \hyperref[prb:s-t-max-flow]{max-flow} computations on \(G\). It's also easy to show that computing \(S_i\)'s in \autoref{algo:isolating-cut-U} can be done in \(O((m+n) \log k)\) time given \((X_{\ell } , Y_{\ell } )\) for \(\ell \in [\lceil \log k \rceil ]\). However, \autoref{algo:isolating-cut-H} and \autoref{algo:isolating-cut-min-cut} seem to require \(k\) \hyperref[prb:s-t-max-flow]{max-flow} computations.

	\begin{claim}
		In total, \autoref{algo:isolating-cut-min-cut} only requires \(O(\log k)\) \hyperref[prb:s-t-max-flow]{max-flow} computations.
	\end{claim}
	\begin{explanation}
		Let us understand the size of \(H_i\). It has \(n_i + 1\) vertices where \(n_i = \lvert S_i \rvert \), and it has \(m_i\) edges where \(m_i = \lvert E(S_i) \rvert + \lvert \delta (S_i) \rvert \). Thus, the running time of \hyperref[prb:s-t-max-flow]{max-flow} on \(H_i\) is \(T(n_i + 1, m_i)\) where \(T(a, b)\) is the running time of \hyperref[prb:s-t-max-flow]{max-flow} on graph with \(a\) nodes and \(b\) edges. We observe that \(\sum_{i} (n_i + 1) \leq 2n\) since \(S_i\)'s are disjoint, while \(\sum_{i} m_i \leq 2m\): consider any edge \(uv \in E\). If \(uv \in E(S_i)\) for some \(i\), then it does not contribute to any other \(H_j\). If \(uv \in \delta (S_i)\) for some \(i\), then it can be in \(\delta (S_j)\) for only one more index \(j \neq i\).

		Thus, the total time to compute all \(k\) \hyperref[prb:s-t-max-flow]{max-flows} is \(\sum_{i} T(n_i, m_i) \leq T(2n, 2m)\) under reasonable assumption, specifically, \(T(a, b)\) is super-additive.\footnote{Formally, we first create a single \(H\) that includes each \(H_i\) as a copy in it, and we can run a single \hyperref[prb:s-t-max-flow]{max-flow} on \(H\) to recover all the \hyperref[prb:s-t-max-flow]{max-flow} values in each \(H_i\). \(H\) will have \(O(n)\) vertices and \(O(m)\) edges.}
	\end{explanation}
	With the correctness of \autoref{algo:isolating-cut}, the theorem is proved.
\end{proof}

We see that this could have been discovered many years ago in terms of its simplicity. \autoref{algo:isolating-cut} has been very influential in the last few years for a number of problems.

\begin{note}
	Another perspective of the bi-partitions is that they are a way to \emph{derandomize} a natural randomized algorithm that picks some \(O(\log k)\) bi-partitions of \(T\) at random and computes the cuts between them. With high probability, every \(t_i, t_j\) with \(i \neq j\) will be separated in at least on of the random bi-partitions.
\end{note}

\begin{remark}
	The core idea of \hyperref[prb:isolating-cut]{isolating cuts} relies only on \hyperref[def:submodular]{submodularity} and symmetry, thus, this applies in much more generality and to several other problems. This is explicitly discussed in~\cite{chekuri2021isolating}, though the ideas are implicit in~\cite{li2020deterministic}.
\end{remark}

\subsubsection{Randomized Algorithm for Steiner Min-Cut via Isolating Cuts}
\hyperref[prb:isolating-cut]{Isolating cut} naturally lead to a simple randomized algorithm for \hyperref[prb:Steiner-min-cut]{Steiner min-cut}. The basic idea is quite simple. Consider an optimum \hyperref[prb:Steiner-min-cut]{Steiner min-cut} \((S, V\setminus S)\) and let \(T_1 \coloneqq S \cap T\) and \(T_2 \coloneqq (V \setminus S) \cap T\), with \(k_1 = \lvert T_1 \rvert \) and \(k_2 = \lvert T_2 \rvert \). We may assume that \(1 \leq k_1 \leq k_2\).

\begin{note}
	\((S, V\setminus S)\) is a \hyperref[prb:s-t-min-cut]{\(t_i\)-\(t_j\) min-cut} for any \(t_i \in T_1, t_j \in T_2\) since otherwise, a lower-cost cut exists.
\end{note}

The basic intuition is the following.

\begin{intuition}
	If we can sample exactly one terminal in one side of the \hyperref[prb:Steiner-min-cut]{Steiner min-cut}, then we can simply use the \hyperref[prb:isolating-cut]{isolating cut} to recover the \hyperref[prb:Steiner-min-cut]{Steiner min-cut}.
\end{intuition}

Say we know \(k_1\). We can sample each terminal in \(T\) independently with probability \(1 / k_1\) to obtain \(T^{\prime} \subseteq T\) such that with constant probability, \(\lvert T^{\prime} \cap T_1 \rvert = 1\) and \(\lvert T^{\prime} \cap T_2 \rvert \geq 1\) (recall \(k_1 \leq k_2\)). Suppose \(T^{\prime} \) satisfies these properties and let \(T^{\prime} \cap T_1 = \{ t_i \} \). Then, \((S, V\setminus S)\) is a minimum cost \hyperref[prb:isolating-cut]{\(t_i\)-isolating cut} w.r.t.\ \(T^{\prime} \). Hence, by computing \hyperref[prb:isolating-cut]{\(t_i\)-isolating cuts} for all \(t_i \in T^{\prime} \) and choosing the cheapest one identifies the \hyperref[prb:Steiner-min-cut]{Steiner min-cut} for \(T\). The problem is that we don't know \(k_1\), and trying all possible values for \(k_1\) (from \(1\) to \(k / 2\)) will be too expensive.

\begin{intuition}
	The above sampling procedure is robust: if we sample with probability, say, \(1 / 2k_1\), everything still happens with constant probability. Hence, we only need to try \(k_i = 2^i\), i.e., \(O(\log k)\) different sampling probabilities.
\end{intuition}

We formally describe this algorithm as follows.

\begin{algorithm}[H]\label{algo:Steiner-min-cut}
	\DontPrintSemicolon{}
	\caption{\hyperref[prb:Steiner-min-cut]{Steiner Min-Cut}}
	\KwData{A connected graph \(G = (V, E)\) with edge capacity \(c \colon E \to \mathbb{R} _{+} \), terminal \(T = \{ t_i \} _{i=1}^{k}\)}
	\KwResult{A possible \hyperref[prb:Steiner-min-cut]{Steiner min-cut} \((S^{\ast} , V \setminus S^{\ast} )\)}
	\SetKwFunction{sample}{Sample}
	\SetKwFunction{isolatingcut}{\hyperref[algo:isolating-cut]{Isolating-Cut}}
	\SetKwFunction{mincost}{Min-Cost}
	\BlankLine

	\(S^{\ast} \gets \varnothing \)\Comment*[r]{Initialize \hyperref[prb:Steiner-min-cut]{Steiner min-cut}}
	\For(){\(i = 0, \dots , \lceil \log k \rceil \)}{
	\(T^{\prime} \gets\)\sample{\(T\), \(1 / 2^i\)}\Comment*[r]{Sample each terminal in \(T\) with probability \(1 / 2^i\)}
	\(\{ (S_i^{\ast} , V\setminus S_i^{\ast} ) \}_{i=1}^{\lvert T^{\prime} \rvert } \gets\)\isolatingcut{\(G\), \(c\), \(T^{\prime} \)}\;
	\(S^{\ast} \gets \)\mincost{\(\{ (S_i^{\ast} , V\setminus S_i^{\ast}) \}_{i=1}^{\lvert T^{\prime} \rvert } \cup \{ (S^{\ast} , V \setminus S^{\ast} ) \} \)}\Comment*[r]{Update minimum cost cut}
	}
	\Return{\((S^{\ast} , V\setminus S^{\ast} )\)}\;
\end{algorithm}

We now formally prove the robustness we have mentioned.

\begin{lemma}\label{lma:algo:Steiner-min-cut}
	\autoref{algo:Steiner-min-cut} finds the \hyperref[prb:Steiner-min-cut]{Steiner min-cut} for \(T\) with a constant probability.
\end{lemma}
\begin{proof}
	We see that for \(k_1 = 1\), \autoref{algo:Steiner-min-cut} is correct (deterministically) since \(i\) can only be \(0\) and \(T^{\prime} = T\). Hence, let \(k_1 > 1\). Consider the case that \(1 / 2^{i+1} < 1 / k_1 \leq 1 / 2^i\), where \(i\) will be tried at some point during \(i=0\) to \(\lceil \log k \rceil \) since \(1 \leq k_1 \leq k / 2\). Let \(\ell = 2^i\), i.e., \(\ell \leq k_1 \leq 2 \ell \).

	Now, let \(\mathcal{E} _1\) be the event that \(\lvert T_1 \cap T^{\prime} \rvert = 1\), i.e., exactly one terminal from \(T_1\) is chosen. Then
	\[
		\Pr(\mathcal{E} _1)
		= k_1 \cdot \frac{1}{\ell } \cdot \left( 1 - \frac{1}{\ell } \right) ^{k_1 - 1}
		\geq \left( 1 - \frac{1}{\ell } \right) ^{2\ell }
		\geq \frac{1}{e^2}.
	\]
	On the other hand, let \(\mathcal{E} _2\) be the event that \(T_2 \cap T^{\prime} \neq \varnothing \). We see that
	\[
		\Pr(\mathcal{E} _2)
		\geq 1 - \left( 1 - \frac{1}{\ell } \right) ^{k_2}
		\geq \left( 1 - \frac{1}{\ell } \right) ^{\ell }
		\geq 1 - \frac{1}{e}.
	\]
	Since \(T_1\) and \(T_2\) are disjoint, \(\mathcal{E} _1\) and \(\mathcal{E} _2\) are independent, we have
	\[
		\Pr(\mathcal{E} _1 \cap \mathcal{E} _2)
		\geq \left( 1 - \frac{1}{e} \right) \cdot \frac{1}{e^2},
	\]
	which is a constant.
\end{proof}

\begin{theorem}\label{thm:Steiner-min-cut}
	There is a randomized algorithm that given \(G=(V, E)\) and terminal set \(T \subseteq V\) of size \(k\), outputs the \hyperref[prb:Steiner-min-cut]{Steiner min-cut} with high probability using \(O(\log^2 k \log n)\) \hyperref[prb:s-t-max-flow]{max-flow} computations on graphs with \(\lvert V \rvert \) vertices and \(\lvert E \rvert \) edges.
\end{theorem}
\begin{proof}
	From \autoref{lma:algo:Steiner-min-cut}, \autoref{algo:Steiner-min-cut} successes with a constant probability. We further boost the overall success probability by rerunning \autoref{algo:Steiner-min-cut} \(\Theta (\log n)\) times. With \autoref{thm:isolating-min-cut}, this requires \(O(\log ^2k \log n)\) \hyperref[prb:s-t-max-flow]{max-flow} computations.
\end{proof}

\begin{remark}[Deterministic algorithm]
	Li and Panigraphy~\cite{li2020deterministic} also developed deterministic \hyperref[prb:global-min-cut]{min-cut} and \hyperref[prb:Steiner-min-cut]{Steiner min-cut} algorithms using additional ideas based on \hyperref[def:expander-decomposition]{expander decomposition}.
\end{remark}