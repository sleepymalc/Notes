\lecture{12}{11 Oct.\ 12:30}{Page Rank, Markov Chain and Randomness}
Recall that we want to measure the centrality of a network. We did this by introducing \autoref{thm:spectral-theorem} and \autoref{thm:Perron-Frobenius-theorem}.

We first look at following two problems.
\begin{problem}[Eigenvector centrality]
For \(A\) be an \hyperref[def:adjacency-matrix]{adjacency matrix}, which is a non-negative matrix with \(r(0) = \vec{1}\) and
\[
	r(k) = Ar(k - 1), \qquad \forall k = 1\dots
\]

Then if it is \hyperref[def:irreducible]{irreducible} and \hyperref[def:aperiodic]{aperiodic}, then
\[
	\lim_{k\to \infty } \frac{r(k)}{(\rho(A))^k} = v(w^{\top} r(0))
\]
where \(\rho(A)\) is the unique \hyperref[def:spectral-radius]{spectral radius}, \(v\) is the right \hyperref[def:eigenvector]{eigenvector} of \(A\) and \(w\) is the left \hyperref[def:eigenvector]{eigenvector} of \(A\), and \(w^{\top}v = 1\) for \(\rho(A)\).

We then have
\[
	\lim_{k\to \infty}\frac{A^k}{(\rho(A))^k} = vw^{\top}.
\]

\begin{remark}
	Notice that
	\begin{itemize}
		\item \(v\) would be the \hyperref[def:eigenvector]{eigenvector} centrality measure.
		\item \(r^{\ast} = A r^{\ast}\) need not hold because \(1\) need not be an \hyperref[def:eigenvalue]{eigenvalue}.
		\item Since
		      \[
			      (r(k))_i = \sum\limits_{j} A_{ij}r_{j}(k - 1) = \sum\limits_{j\colon i\to j} r_j(k-1),
		      \]
		      so we see that nodes that either point to many nodes, or important nodes or both, will have higher value.
	\end{itemize}
\end{remark}
\end{problem}

\begin{problem}[Katz centrality]
Again, consider \(r(k) = Ar(k - 1)\), but this time we modify the equation to be
\[
	r(k) = \alpha Ar(k - 1) + \beta \vec{1}
\]
where \(\alpha\) is aiming to dampen the degree, and \(\beta\) is aiming to add a constants weight for each node to increase the fairness. Similarly, any solution will satisfy
\[
	r^{\ast} = \alpha Ar^{\ast} + \beta \vec{1}\iff (I - \alpha A)r^{\ast} = \beta \vec{1}.
\]
\begin{definition}[Katz centrality]\label{def:Katz-centrality}
	The solution \(r^{\ast} \) of \(r^{\ast} = \alpha Ar^{\ast} + \beta \vec{1}\) is called the \emph{Katz centrality} if it exits.
\end{definition}

Now, if \(I - \alpha A\) is invertible, then
\[
	r^{\ast} = \beta(I - \alpha A)^{-1} \vec{1}.
\]
Noting that
\[
	\det(\lambda I - A) = 0 \iff \det(I - \lambda A) = 0,
\]
which implies \(\alpha\) should not be the inverse of an \hyperref[def:eigenvalue]{eigenvalue} of \(A\). Also, we  need that \(r^{\ast}\) to be positive.

\begin{figure}[H]
	\centering
	\incfig{katz-centrality}
	\caption{Katz Centrality}
	\label{fig:katz-centrality}
\end{figure}

Then for all \(1/\alpha > \rho(A) \iff \alpha\rho(A)<1 \iff \rho(\alpha A)<1\), \(\alpha\) can't be the inverse of any \hyperref[def:eigenvalue]{eigenvalues} of \(A\) since we see that \(\alpha A\) is non-negative with \hyperref[def:spectral-radius]{spectral radius} \(<1\).

Now, if \(\alpha A\) is non-negative with \hyperref[def:spectral-radius]{spectral radius} strictly less than one, then we have
\[
	(I - \alpha A)^{-1} = I + (\alpha A) + (\alpha A)^2 + \dots
\]
just like the geometry series of \(\frac{1}{1-k}\) for \(\left\vert k \right\vert <1 \). We then have
\[
	r^* = \beta\left(\sum\limits_{i=0}^{\infty} (\alpha A)^i\right)\vec{1}.
\]

\begin{remark}
	Since
	\[
		\rho(A) \leq \text{ the maximum of row sum of }A = \text{ the highest out-degree},
	\]
	we see that
	\[
		\underline{\alpha \times \text{the highest out-degree}<1}
	\]
	is a sufficient condition for this to hold.
\end{remark}

\begin{note}
	\hyperref[def:Katz-centrality]{Katz centrality} is commonly used.
\end{note}
\end{problem}

\chapter{Stochastic Process}
The motivation is simple: we want to understand the scaled page rank via another viewpoint, i.e., via \hyperref[def:Markov-chain]{Markov chain}. This is a special kind of \hyperref[def:stochastic-process]{stochastic process}, and surprisingly, this can interpret the scaled page rank algorithm nicely.

\begin{prev}
	We have seen that \(\widetilde{N}(s)\) is formed in a way such that
	\[
		\widetilde{r}(k) = \widetilde{N}(s)^{\top}\widetilde{r}(k - 1)
	\]
	with \(\widetilde{r}(0) = \frac{1}{\left\vert \mathcal{V} \right\vert }\vec{1}\), where \(\widetilde{r}(k)\) is the vector form of the scaled page rank. Then, we have
	\[
		\widetilde{r}(k) = \left(\widetilde{N}(s)^{\top}\right)^k r(0),
	\]
	which suggests that an \textbf{iterated algorithm} known as \emph{power iteration} or \emph{power method}. We see that this will provide a uniform decrease in the relative error of the entries. Specifically, let \(v\) be the left \hyperref[def:eigenvalue]{eigenvalues}, then we have
	\[
		\max_{i\in \mathcal{V}}\left\vert (r(k))_i - v_i\right\vert \leq c_0 s^k
	\]
	where \(s\) is the scaled page rank factor. Then, by using this, if we set the error tolerance as \(\epsilon\), i.e., we want the right-hand side to be less than \(\epsilon \), we have
	\[
		\#\text{iteration} = \frac{\log(\epsilon)}{\log(s)}\times \nnz(N),
	\]
	where \(\nnz(N)\) is the number of non-zero elements in \(N\).
	\begin{remark}
		A sparse \hyperref[def:graph]{graph} like Internet will typically have
		\[
			\nnz(N)\sim\Theta(n^2),
		\]
		where \(n\) is the number of the nodes.
	\end{remark}
\end{prev}


\section{Probability}
To introduce \hyperref[def:Markov-chain]{Markov chain}, we start with probability.
\begin{prev}[Probaility review]
	We let
	\begin{itemize}
		\item \(\Sigma\) being our sample space.
		\item \(\mathcal{F}\) being the \(\sigma\)-algebra (\(\sigma \)-field). This is essentially just a collection of events subsets of the sample space.
		\item \(\Pr \colon \mathcal{F} \to [0, 1]\) is the probability with values in \([0, 1]\) assigned to events.
	\end{itemize}
	For further and rigorous review, see \href{https://pbb.wtf/posts/Notes#real-analysis-math597-umich}{Real Analysis note (MATH 597)}.
\end{prev}

We first see some examples of discrete cases.
\begin{eg}[Coin toss]
	Let \(\Omega = \{\Head, \Tail\}\) corresponding to coin toss, where \(\Head\) is head, \(\Tail\) is tail. We see that
	\[
		\mathcal{F} = \{\varnothing , \{\Head \}, \{\Tail \}, \{\Head , \Tail \}\}.
	\]
	If we let the probability of event \(\Head \) as \(p\), then we have
	\[
		\Pr(\varnothing ) = 0,\quad \Pr(\{\Head\}) = p,\quad \Pr(\{\Tail \}) = 1 - p,\quad \Pr(\{\Head , \Tail \}) = 1.
	\]
\end{eg}

\begin{eg}[Dice toss]
	Let \(\Omega = \{1, 2, 3, 4, 5, 6\}\) corresponding to faces of a die. Then \(\mathcal{F} \) is the power set of \(\Omega \). If the die is fair, then \(\mathbb{P} \) is so-called uniform distribution, which assign an equal value to every event in \(\Omega \). For example,
	\[
		\Pr(\{1, 2, 3\}) = \frac{\left\vert \{1, 2, 3\} \right\vert }{6} = \frac{3}{6} = \frac{1}{2}.
	\]
\end{eg}

For continuous cases, we have the following examples.
\begin{eg}[Uniform distribution]
	Let \(\Omega = [0, 1]\), and \(\mathcal{F}\) is the Borel\footnote{Borel usually means the standard topology on Euclidean space.} \(\sigma \)-algebra which includes all intervals in \([0, 1]\). If we let \(\mathbb{P} \) be the uniform distribution on \([0, 1]\), for every \(x\in [0, 1]\), we have
	\[
		\Pr([0, x]) = x.
	\]
	If we define \(F(x)\coloneqq \Pr([0, x]) \), this is known as the cumulative distribution function, of CDF in short.
\end{eg}

\begin{eg}[Exponential distribution]
	Let \(\Omega = [0, \infty )\), and let \(\mathcal{F} \) be the Borel \(\sigma \)-algebra with \(\mathbb{P} \) the exponential distribution with parameter \(\lambda \in (0, \infty )\). Then for all \(x\in [0, \infty )\), the CDF is defined as
	\[
		F(x) = \Pr([0, x]) = 1 - e^{-\lambda x}.
	\]
\end{eg}

\begin{eg}[Normal distribution]
	Let \(\Omega = \mathbb{R} = (-\infty , +\infty )\), and \(\mathcal{F}\) be the Borel \(\sigma\)-algebra with \(\mathbb{P}\) be the normal distribution with mean \(\mu \) and variance \(\sigma ^{2} \). Then for all \(x\in (-\infty , +\infty )\), the CDF is defined as
	\[
		F(x) = \Pr\left( (-\infty , x] \right)  = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi \sigma ^{2} } } e^{- \frac{(x^\prime  - \mu )^{2} }{2 \sigma ^{2} }} \,\mathrm{d}x^\prime.
	\]
	Since this is an important distribution, we denote the normal distribution with mean \(\mu\) and variance \(\sigma ^{2} \) as \(\mathcal{N} (\mu , \sigma ^{2} )\).
\end{eg}

There are some important properties of probability. Firstly, for two mutually disjoint sets \(A\) and \(B\in\mathcal{F}\) such that \(A\cap B = \varnothing\), we have
\[
	\Pr(A\cup B) = \Pr(A) + \Pr(B).
\]
This can be easily generalized to any finite collection of mutually disjoint subsets
\[
	A_1, A_2, \dots , A_n
\]
such that
\[
	A_i \cup A_j = \begin{dcases}
		A_i,         & \text{ if }i = j    \\
		\varnothing, & \text{ if }i\neq j.
	\end{dcases}
\]
We then have
\[
	\Pr(\bigcup\limits_{i = 1}^n A_{i}) = \sum\limits_{i=1}^{n} \Pr(A_{i}).
\]
\begin{remark}
	Axioms of probability says that this extends to countably infinity collections of mutually disjoint sets. Namely, consider mutually disjoint sets
	\[
		A_1, A_2, \dots,
	\]
	we have
	\[
		\Pr(\bigcup\limits_{i=1}^{\infty} A_{i}) = \sum\limits_{i=1}^{\infty} \Pr(A_{i}) = \lim_{n \to \infty} \sum\limits_{i=1}^{\infty} \Pr(A_{i}).
	\]
	Another important property is that \(\mathcal{F}\) is closed under (countably many) intersections.
\end{remark}

Also, Let \(\Omega\) be the sample space, then we have \(\Pr(\Omega) = 1\). This implies
\[
	\Pr(\varnothing ) = 0.
\]

Further, if \(A\in\mathcal{F}\), then \(A^{c}\in\mathcal{F}\) and \(A\cap A^{c}= \varnothing \). We then see
\[
	\Pr(\Omega) = 1 = \Pr(A\cup A^{c}) = \Pr(A) + \Pr(A^{c}) \implies \Pr(A^{c}) = 1 - \Pr(A).
\]

\begin{note}
	Notice that \(\varnothing  = \Omega^{c}\) in our convention.
\end{note}

Lastly, we have the following definition.
\begin{definition}[Mutually independent]\label{def:mutually-independent}
	We say two sets \(A\), \(B\) are \emph{mutually independent} sets if
	\[
		\Pr(A\cap B) = \Pr(A)\Pr(B).
	\]
	Also, we have similar definition for countably infinite collections of sets. We say a countably infinite collection of sets is mutually independent if any finite sub-collection is independent. Namely, for any finite index set \(K\subsetneq \mathbb{N}\) with \(\left\vert K \right\vert < \infty \),
	\[
		\Pr(\bigcap\limits_{k\in K} A_k) = \prod_{k\in K} \Pr(A_k).
	\]
\end{definition}

\subsection{Random Variable}
Let's start with a definition.
\begin{definition}[Random variable]\label{def:random-variable}
	A \emph{random variable} is just a mappings (functions) from the sample space to real number \(\mathbb{R} \).
\end{definition}

Typically, we let \(X\colon \Omega\to \mathbb{R}\) be measurable and denote the Borel \(\sigma\)-algebra on \(\mathbb{R} \) as \(\mathcal{B}(\mathbb{R})\). In particular, we have \((-\infty , x] \in \mathcal{B}(\mathbb{R})\), or more generally, for all \(x\in (-\infty , +\infty )\), \(\left\{\omega\colon X(\omega)\leq x\right\}\in\mathcal{F}\). This allows us to define the cumulative density function of \(x\). In particular,
\[
	\Pr_X((-\infty , x)) = \Pr(\left\{\omega\colon X(\omega)\leq x\right\}).
\]

Same as probability, we can define \hyperref[def:independent]{independence} of a collection of \hyperref[def:random-variable]{random variables}.
\begin{definition}[Independent]\label{def:independent}
	Let \(X\) and \(Y\) be two \hyperref[def:random-variable]{random variables}. We say \(X, Y\) are \emph{independent} if for all \(A, B\in \mathcal{B} (\mathbb{R} )\),
	\[
		\Pr(\left\{x\in A\right\}\cap \left\{y\in B\right\}) = \Pr(\left\{x\in A\right\})\Pr(\left\{y\in B\right\}).
	\]
\end{definition}
\begin{remark}
	Notice that we are abusing the notation here. In the definition, \(x\) is sampled from \(X\) and \(y\) is sampled from \(Y\) without explicitly mentioning. In reality, we have
	\[
		\left\{x\in A\right\}\cup \left\{y\in B\right\} = \left\{\omega\in \Omega\colon X(\omega)\in A\land Y(\omega)\in B\right\},
	\]
	we see that we need
	\[
		\left\{\omega\in \Omega\colon X(\omega)\in A\right\}\in\mathcal{F} \text{ and }\left\{\omega\in \Omega\colon Y(\omega)\in B\right\}\in\mathcal{F}.
	\]
\end{remark}

\begin{note}[Independence via expectation]
	We can also view \hyperref[def:independent]{independence} from the probability density function \(f_X(x)\). We have
	\[
		\mathbb{E}\left[f(x) \right] \coloneqq \begin{dcases}
			\sum\limits_{i=1}^{n} f_X(x_i)\Pr(x = x_i) \\
			\int_{-\infty }^{\infty }f_X(x)\,\mathrm{d}\underbrace{F_X(x)}_{\mathrm{CDF}}
		\end{dcases}
	\]
	where \(f_X(x)\) is probability density function. Then in this case, we say \(X\) and \(Y\) are \hyperref[def:independent]{independent} if for any \(f\) and \(g\),
	\[
		\mathbb{E}\left[f(x)g(y) \right] = \mathbb{E}\left[f(x) \right] \mathbb{E}\left[g(y) \right] .
	\]
\end{note}

\begin{eg}
	Let \(f_X(x) = x^2\) and \(g_Y(y) = y^3\). Then if \(X\) and \(Y\) are \hyperref[def:independent]{independent}, we will have
	\[
		\mathbb{E}\left[x^2 y^3 \right] = \mathbb{E}\left[x^2 \right] \mathbb{E}\left[y^3 \right].
	\]
\end{eg}

\begin{remark}
	Again, we have similar definition for countably infinite collection of \hyperref[def:random-variable]{random variables} being \hyperref[def:independent]{independent}. Let \hyperref[def:random-variable]{random variables} being
	\[
		X_1, X_2, \dots
	\]
	associated with the probability density function \(f_1, f_2, \dots\). Then, we say this collection of \hyperref[def:random-variable]{random variables} is \hyperref[def:independent]{independent} if for any finite sub-collection is \hyperref[def:independent]{independent}. Namely, for any finite index set \(K\subsetneq\mathbb{N}\) such that \(\left\vert K \right\vert < \infty \),
	\[
		\mathbb{E}\left[\prod\limits_{k\in K} f_k(x_k) \right] = \prod\limits_{k\in K} \mathbb{E}\left[f_k(x_k) \right] .
	\]
\end{remark}

\section{Stochastic Process}
We now define
\begin{definition}[Stochastic process]\label{def:stochastic-process}
	\emph{Stochastic process}\footnote{Sometimes random process}, is a collection of \hyperref[def:random-variable]{random variable} induced by a discrete (time) index
	\[
		X_1, X_2, X_3, \dots.
	\]
	In a compact way, we can write \(\{X_i\}_{i = 1}^{\infty }\).
\end{definition}

Similarly to the \hyperref[def:independent]{independent} in probability, there is an analogous definition.

\begin{definition}[i.i.d.]\label{def:i.i.d.}
	A stochastic process is said to be \emph{i.i.d.} if its collection of \hyperref[def:random-variable]{random variable} are all \hyperref[def:independent]{independent} and identically distributed.
\end{definition}