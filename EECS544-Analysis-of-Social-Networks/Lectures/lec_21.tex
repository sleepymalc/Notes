\lecture{21}{17 Nov.\ 12:30}{Bayesian Game}
We first introduce a new notion.
\begin{definition}[Social welfare]\label{def:social-welfare}.
	The \emph{social welfare} is the sum of \hyperref[def:reward]{payoffs} among all \hyperref[def:player]{players}.
\end{definition}
\begin{prev}
	We look back some \hyperref[def:game]{games} and introduce another measure of \hyperref[def:Nash-equilibrium]{Nash equilibrium}.
	\begin{itemize}
		\item \hyperref[def:coordination-game]{Coordination game}. The \hyperref[def:payoff-matrix]{payoff matrix} is defined as
		      \begin{table}[H]
			      \centering
			      \setlength{\extrarowheight}{2pt}
			      \begin{tabular}{cc|c|c|}
				                                                     & \multicolumn{1}{c}{} & \multicolumn{2}{c}{\hyperref[def:player]{Player} 2}                           \\
				                                                     & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$S$}                             & \multicolumn{1}{c}{$H$} \\\cline{3-4}
				      \multirow{2}*{\hyperref[def:player]{Player} 1} & $S$                  & $(5, 5)$                                            & $(0, 3)$                \\\cline{3-4}
				                                                     & $H$                  & $(3, 0)$                                            & $(3, 3)$                \\\cline{3-4}
			      \end{tabular}
		      \end{table}
		      As we can see, there are two \hyperref[def:Nash-equilibrium]{Nash equilibrium} \((S, S)\) and \((H, H)\) with \hyperref[def:reward]{payoffs} \((5, 5)\) and \((3, 3)\) respectively. If we consider \hyperref[def:social-welfare]{social welfare}, one will choose to play \((S, S)\) with \hyperref[def:social-welfare]{social welfare} as \(10\) rather than \(6\).
		\item \hyperref[eg:prisoner-dilemma]{Prisoner's dilemma}.
		      \begin{table}[H]
			      \centering
			      \setlength{\extrarowheight}{2pt}
			      \begin{tabular}{cc|c|c|}
				                                                     & \multicolumn{1}{c}{} & \multicolumn{2}{c}{\hyperref[def:player]{Player} 2}                                    \\
				                                                     & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$\mathrm{NC}$}                   & \multicolumn{1}{c}{$\mathrm{C}$} \\\cline{3-4}
				      \multirow{2}*{\hyperref[def:player]{Player} 1} & $\mathrm{NC}$        & $(-1, -1)$                                          & $(-10, 0)$                       \\\cline{3-4}
				                                                     & $\mathrm{C}$         & $(0, -10)$                                          & $(-4, -4)$                       \\\cline{3-4}
			      \end{tabular}
		      \end{table}
		      We see that \((\mathrm{C} , \mathrm{C} )\) is the only \hyperref[def:Nash-equilibrium]{Nash equilibrium}, but \((\mathrm{NC}, \mathrm{NC} )\) is the \hyperref[def:social-welfare]{social welfare} maximization, which is not in the \hyperref[def:Nash-equilibrium]{Nash equilibrium}.
	\end{itemize}
\end{prev}

\begin{remark}
	We say that a \hyperref[def:Nash-equilibrium]{Nash equilibrium} \emph{reaches \hyperref[def:social-welfare]{social welfare}} if it's a maximizer of the \hyperref[def:social-welfare]{social welfare}.
\end{remark}

\subsection{Operating Points}
Let \(i\in \mathcal{I} \) be the set of \hyperref[def:player]{players}, and \(P_{i}\) be the corresponding distribution of \hyperref[def:mixed-strategy]{strategy} on \hyperref[def:player]{player} \(i\). Then we see the definition of the so-called \hyperref[def:operating-point]{operating points}.

\begin{definition}[Operating point]\label{def:operating-point}
	An \emph{operating point} is a vector of \hyperref[def:reward]{rewards} of \hyperref[def:player]{players} such that we cannot increase the \hyperref[def:reward]{payoff} of one \hyperref[def:player]{agent} without decreasing the \hyperref[def:reward]{payoff} of at least one other \hyperref[def:player]{agent}.
\end{definition}

Let \(P\) denotes the set of operating points. From here, we have the following criteria for \hyperref[def:Pareto-optimal]{Pareto Optimal}.

\begin{definition}[Pareto optimal]\label{def:Pareto-optimal}
	A solution is called \emph{Pareto optimal} if no individual or preference criterion can be better off without making at least one individual or preference criterion worse off or without any loss thereof.
	\begin{center}
		\incfig{Pareto-Optimal}
	\end{center}
\end{definition}


\begin{center}
	\incfig{NE-social-welfare}
\end{center}

\begin{note}
	For either \hyperref[def:social-welfare]{social welfare} maximizing or \hyperref[def:Pareto-optimal]{Pareto} \hyperref[def:operating-point]{operating point},
	\begin{itemize}
		\item \hyperref[def:Nash-equilibrium]{Nash equilibrium} needs not achieve either goal.
		\item \hyperref[def:social-welfare]{Social welfare} maximizing points are always \hyperref[def:Pareto-optimal]{Pareto optimal}.
	\end{itemize}
\end{note}

\begin{remark}
	We can (re)design \hyperref[def:game]{games} such that some nice objective is additive, then \hyperref[def:social-welfare]{social welfare} maximization can be achieved, i.e., the goal is that any \hyperref[def:Nash-equilibrium]{Nash equilibrium} should maximize \hyperref[def:social-welfare]{social welfare}.
\end{remark}

Until this point, we only study the \hyperref[def:game]{games} have complete and symmetric information, i.e., \hyperref[common-knowledge]{common knowledge assumption}. Now, we can look at some more complicated cases such that we have an incomplete and/or asymmetric information setting.

\section{Bayesian Game}
We now introduce a new type of \hyperref[def:game]{game} called \hyperref[def:Bayesian-game]{Bayesian game}.

\begin{definition}[Bayesian game]\label{def:Bayesian-game}
	A \emph{Bayesian game} is an asymmetric/incomplete \hyperref[def:game]{games}.
\end{definition}
\begin{intuition}
	Since we need to use \href{https://en.wikipedia.org/wiki/Bayes%27_theorem}{Bayesian Theorem} to analysis \hyperref[def:Bayesian-game]{Bayesian games}, so it gets its name.
\end{intuition}

\begin{eg}[Auction]
	A typical example of a \hyperref[def:Bayesian-game]{Bayesian game} is \hyperref[ch:auctions]{auctions}, which we'll study in depth later.
\end{eg}

An important difference is that in \hyperref[def:Bayesian-game]{Bayesian games}, \underline{nation is also a \hyperref[def:player]{player}}. Further, randomness decides the state of everyone and people may know their state but not of the others.

\begin{note}
	Randomness here is different from \hyperref[def:mixed-strategy]{mixed strategies}. This happens \textbf{at the beginning}.
\end{note}

\subsection{Basic Setup}
We now try to mathematically model a \hyperref[def:Bayesian-game]{Bayesian game}.

\begin{definition}[Methematical Bayesian game]\label{def:mathematical-Bayesian-game}
	Let \(\mathcal{I} \) denotes the set of \hyperref[def:player]{players}, and \(I = \left\vert \mathcal{I}  \right\vert \). Let each \hyperref[def:player]{player \(i\)} has a \hyperref[def:type]{type} defined as follows.

	\begin{definition}[Type]\label{def:type}
		The \emph{type} of a \hyperref[def:player]{player} \(i\), denotes as \(\tau_{i}\in T_{i}\), is chosen with distribution
		\(\pi_i\) such that
		\[
			\Pr(\tau_{i} = t_{i}) = \pi_i(t_{i}) .
		\]
	\end{definition}

	And also, we have the set of \hyperref[def:strategy]{actions} \(\mathcal{S}_{i}\), and the set of feasible \hyperref[def:strategy]{actions}
	\[
		c_{i}(t_{i})\in \mathcal{S}_{i}.
	\]

	Furthermore, the \hyperref[def:reward]{utility} of \hyperref[def:player]{player} \(i\) is
	\[
		u_{i}(t_1, s_1, t_2, s_2, \dots , t_I, s_I),
	\]
	where we need \hyperref[def:type]{types} and \hyperref[def:strategy]{actions} of all \hyperref[def:player]{players} to determine this. Also, we have
	\[
		\vec{t}\coloneqq (t_1, \dots , t_I),\quad \vec{s} \coloneqq (s_1, \dots , s_I),
	\]
	with the common notation for \(-i\), namely
	\[
		\vec{t}_{-i} \coloneqq (t_1, \dots , t_{i-1}, t_{i+1}, \dots , t_{I}),\quad \vec{s}_{-i} \coloneqq (s_1, \dots , s_{i-1}, s_{i+1}, \dots , s_{I}).
	\]

	We see that \hyperref[def:player]{player} \(i\) has to choose a \hyperref[def:strategy]{strategy} \(\sigma_{i}\colon T_{i}\to \mathcal{S}_{i}\) such that
	\[
		\forall t_{i}\in T_{i}, \text{ choose }\sigma_{i}(t_{i})\in c_{i}(t_{i})\subseteq \mathcal{S}_{i}.
	\]
\end{definition}

\begin{intuition}
	We are simply picking functions as \hyperref[def:strategy]{strategies}.
\end{intuition}

\begin{eg}
	Let \(T_{i} = \mathbb{R}_+ = [0, +\infty )\) be non-negative real number. Let
	\(\sigma_{i}(t_{i}) = \min(100, t_{i})\) and \(\mathcal{S}_{i} = \mathbb{R}_+\).
	\begin{center}
		\incfig{action-function-eg}
	\end{center}
\end{eg}

Then we can have so-called \hyperref[def:independent-types-model]{independent types model}.
\begin{definition}[Independent types model]\label{def:independent-types-model}
	An \emph{independent types model} is a \hyperref[def:mathematical-Bayesian-game]{Bayesian game} such that the \hyperref[def:type]{types} \(\tau _i\),
	\(i = 1, \dots  , I\) are a set of \hyperref[def:independent]{mutually independent} \hyperref[def:random-variable]{variables}.
\end{definition}

\begin{remark}
	For an \hyperref[def:independent-types-model]{independent types model}, we have
	\[
		\Pr(\tau_{1} = t_1, \dots , \tau_{I} = t_{I})=\prod\limits_{i = 1}^{I} \pi_{i}(t_{i}).
	\]
\end{remark}

We see that we can express all \hyperref[def:mathematical-game]{games} we have previously seen like follows. Let \(T_{i} = \left\{i\right\}\), and
\(c_{i}(i) = \mathcal{S}_{i}\) with \hyperref[def:type]{type} being \(\pi_i(i) = 1\) such that
\[
	u_{i}(1, s_1, 2, s_2, \dots , I, s_I) = u_{i}(s_1, s_2, \dots , s_I).
\]

Now we define the notions of incomplete information.
\begin{definition}[Ex-ante]\label{def:ex-ante}
	No \hyperref[def:player]{player} has information about anyone's \hyperref[def:type]{types} but only the distribution information where \hyperref[def:strategy]{strategy} is chosen. Since we don't know the exact \hyperref[def:reward]{payoffs}, hence we simply take the expected value for the \hyperref[def:reward]{payoffs} based on the \hyperref[def:strategy]{strategy} functions:
	\[
		u_{i}(\sigma_1, \dots , \sigma_I)=\mathbb{E}_{\tau_1, \dots , \tau_I}\left[ u_{i}(\tau_1, \sigma_1(\tau_1), \dots ,\tau_I, \sigma_I(\tau_I) )\right].
	\]
	Then the \hyperref[def:Nash-equilibrium]{Nash equilibrium} is \((\sigma_1^{\ast}, \dots , \sigma_{I}^{\ast})\) such that
	\[
		\underset{i\in\mathcal{I}}{\forall} \ \underset{\sigma_{i}}{\forall}\ u_{i}(\sigma_{i}^{\ast}, \sigma^{\ast}_{-i})\geq u_{i}(\sigma_{i}, \sigma^{\ast}_{-i}).
	\]
	This kind of information mechanism is called \emph{ex-ante}.
\end{definition}
\begin{note}
	The \hyperref[def:ex-ante]{ex-ante} information mechanism can be summarized as follows.
	\begin{enumerate}
		\item Given \hyperref[def:player]{player} \(i, \dots , I\).
		\item \(\sigma_1, \dots , \sigma_{I}\) are chosen: Each \hyperref[def:player]{player} picks \hyperref[def:strategy]{strategy} \(\sigma_{i}\).
		\item \(\tau_1, \dots \tau_{I}\) are realized: Nation chooses \hyperref[def:type]{types} for each \hyperref[def:player]{player}.
		\item \(\underset{i}{\forall }\ s_{i} = \sigma_{i}(\tau_{i})\) is chosen: \hyperref[def:strategy]{Actions} produced, and the
		      \hyperref[def:mathematical-Bayesian-game]{game} is realized.
		\item \(u_{i}(\tau_1, s_1, \dots , \tau_{I}, s_{I})\), namely the \hyperref[def:reward]{payoff} is received.
	\end{enumerate}
\end{note}

\begin{definition}[Interim]\label{def:interim}
	Players get to know their \hyperref[def:type]{types} since Nation play first, and they can reason based on that. So we see that \hyperref[def:player]{player} \(i\) knows \(\tau_{i}\) but not \(\tau_{-i}\). Then \(u_{i}(t_{i}, \sigma_{i}(t_{i}), \sigma_{-i})\) can be described as
	\[
		\begin{split}
			\mathbb{E}_{\tau_{-i}}\left[u_{i}(\underline{t_{i}, \sigma_{i}(t_{i})}, \tau_1, \sigma_1(\tau_1), \dots ,\right. & \underline{\tau_{i-1}, \sigma_{i-1}(\tau_{i-1}),}                                                   \\
			                                                                                                                 & \left.\underline{\tau_{i+1}, \sigma_{i+1}(\tau_{i+1})}, \dots ,\tau_I, \sigma_I(\tau_I) ) \right] .
		\end{split}
	\]
	This kind of information mechanism is called \emph{interim}.
\end{definition}
\begin{note}
	The \hyperref[def:interim]{interim} information mechanism can be summarized as follows.
	\begin{enumerate}
		\item Given \hyperref[def:player]{player} \(i, \dots , I\).
		\item \(\tau_1, \dots \tau_{I}\) are realized: Nation chooses \hyperref[def:type]{types} for each \hyperref[def:player]{player}.
		\item \(\sigma_1, \dots , \sigma_{I}\) are chosen: Each \hyperref[def:player]{player} picks \hyperref[def:strategy]{strategy} \(\sigma_{i}\).
		\item \(\underset{i}{\forall }\ s_{i} = \sigma_{i}(\tau_{i})\) is chosen: \hyperref[def:strategy]{Actions} produced, and the
		      \hyperref[def:mathematical-Bayesian-game]{game} is realized.
		\item \(u_{i}(\tau_1, s_1, \dots , \tau_{I}, s_{I})\), namely the \hyperref[def:reward]{payoff} is received.
	\end{enumerate}
\end{note}

\begin{remark}
	Think about the \hyperref[def:best-response]{best response}. Suppose \(\sigma_{-i}\) is fixed. Then for all \(s_{i}\in \mathcal{S}_{i} \), \(u_{i}(t_{i}, s_{i}, \sigma_{-i})\) is defined.
	\[
		\arg\max_{s_{i}\in\mathcal{S}_{i}} u_{i}(t_{i}, s_{i}, \sigma_{-i})
	\]
	for every \(t_{i}\), \(\BR_{i}(\sigma_{-i}) = \overline{\sigma}_{i}(\sigma_{-i})\). Then we call that \((\sigma^{\ast}_1, \dots , \sigma^{\ast}_I)\) is a \hyperref[def:mathematical-Bayesian-game]{Bayes} \hyperref[def:interim]{interim} \hyperref[def:Nash-equilibrium]{Nash equilibrium} if
	\[
		\underset{i\in \mathcal{I}}{\forall}\ \sigma_{i}^{\ast}\in \overline{\sigma}_{i}(\sigma_{-i}).
	\]
\end{remark}

\begin{definition}[Ex-post]\label{def:ex-post}
	Every \hyperref[def:player]{player} gets to know everyone's \hyperref[def:type]{type}.
	\[
		u_{i}(t_1, \sigma_1(t_1), \dots , t_{I}, \sigma_{I}(t_{I})).
	\]
	This kind of information mechanism is called \emph{ex-post}.
\end{definition}

We will focus on \hyperref[def:interim]{Interim} setting and study \hyperref[ch:auctions]{auctions}, which model mechanism  well.