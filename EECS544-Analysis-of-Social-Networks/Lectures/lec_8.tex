
\lecture{8}{27 Sep.\ 12:30}{Diagonalization}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}
\section{Eigen Decomposition}
From \hyperref[thm:spectral-theorem]{spectral theorem}, we can \textbf{diagonalize} a \hyperref[def:symmetric-matrix]{symmetric matrix} \(A\) via so-called \hyperref[thm:eigen-decomposition]{eigen decomposition} as follows.

\begin{theorem}[Eigen decomposition]\label{thm:eigen-decomposition}
	For a \hyperref[def:symmetric-matrix]{symmetric matrix} \(A\), we can always write
	\[
		A = U D U^{\top},
	\]
	where \(U\) is the \hyperref[def:eigenvalue]{eigenvalues} matrix, and \(D\) is the diagonal matrix of \hyperref[def:eigenvalue]{eigenvalues}. W
\end{theorem}
\begin{proof}
	Firstly, from \autoref{thm:spectral-theorem}, denote \(n\) right \hyperref[def:eigenvector]{eigenvectors} of \(A\) by \(u_1, \dots , u_n\) where \(u_{i} \) corresponds to eigenvalue \(\lambda _i\) such that
	\[
		\lambda _1 \leq \lambda _2 \leq \dots  \leq \lambda _n.
	\]
	Corresponding to this order, we define \(U\) as
	\[
		U = \begin{pmatrix}
			\mid & \mid &        & \mid \\
			u_1  & u_2  & \cdots & u_n  \\
			\mid & \mid &        & \mid \\
		\end{pmatrix},
	\]
	then we have
	\begin{enumerate}[(a)]
		\item \(u_i\) are linear independent, and they form a basis in \(\mathbb{R} ^n\).
		\item \(u_{i} ^{\top} u_{j} ( = \left< u_{i} , u_{j}  \right> ) = 0\) for \(i\neq j\).
		\item \(u_{i} ^{\top} u_{i} = \sum_{j=1}^{n} u_{ij}^{2} = 1 \) (\emph{length} \(= 1\)).
	\end{enumerate}
	\begin{remark}[\(U\) is invertible]
		We see that \(U\) is invertible. Indeed, we have \(U^{-1} = U^{\top} \) since
		\[
			U^{\top}U = \begin{pmatrix}
				\horzbar & u^{\top}_1 & \horzbar \\
				\horzbar & u^{\top}_2 & \horzbar \\
				         & \vdots     &          \\
				\horzbar & v^{\top}_n & \horzbar \\
			\end{pmatrix}\begin{pmatrix}
				\mid & \mid &        & \mid \\
				u_1  & u_2  & \cdots & u_n  \\
				\mid & \mid &        & \mid \\
			\end{pmatrix} = I.
		\]
	\end{remark}
	Then, we claim that we can write \(A\) as \(A = U D U^{\top}\) where \[
		D  = \begin{pmatrix}
			\lambda_1 &           &        &           \\
			          & \lambda_2 &        &           \\
			          &           & \ddots &           \\
			          &           &        & \lambda_n \\
		\end{pmatrix}.
	\]
	To see this, from \(U^{\top} = U^{-1} \), we have \(A U = (U D U^{\top} ) U = U D\) since
	\[
		\begin{split}
			A U = A \begin{pmatrix}
				\mid &        & \mid \\
				u_1  & \cdots & u_n  \\
				\mid &        & \mid \\
			\end{pmatrix} &= \begin{pmatrix}
				\mid  &        & \mid  \\
				A u_1 & \cdots & A u_n \\
				\mid  &        & \mid  \\
			\end{pmatrix}\\ &= \begin{pmatrix}
				\mid           &        & \mid           \\
				\lambda _1 u_1 & \cdots & \lambda _n u_n \\
				\mid           &        & \mid           \\
			\end{pmatrix} = \begin{pmatrix}
				\mid &        & \mid \\
				u_1  & \cdots & u_n  \\
				\mid &        & \mid \\
			\end{pmatrix} \begin{pmatrix}
				\lambda_1 &        &           \\
				          & \ddots &           \\
				          &        & \lambda_n \\
			\end{pmatrix} = UD
		\end{split}
	\]
	Hence we're done.
\end{proof}

\begin{eg}
	Find the \hyperref[def:eigenvalue]{eigenvalue} of
	\[
		A = \begin{pmatrix}
			1 & 0 & 0 \\
			0 & 2 & 1 \\
			0 & 1 & 2 \\
		\end{pmatrix}.
	\]
\end{eg}
\begin{explanation}
	The \hyperref[note:characteristic-equation]{characteristic equation} of \(A\) is
	\[
		\begin{split}
			\det(\lambda I - A) &= \det \left(  \begin{pmatrix}
				\lambda - 1 & 0            & 0             \\
				0           & \lambda -  2 & -1            \\
				0           & -1           & \lambda -   2 \\
			\end{pmatrix}\right)\\
			&= (\lambda - 1)((\lambda - 2 )^2 - 1)\\
			&= (\lambda - 1)(\lambda - 2 - 1)(\lambda - 2 + 1)\\
			&= (\lambda - 1)(\lambda - 3)(\lambda - 1) = 0.
		\end{split}
	\]
	We see that the roots of the \hyperref[note:characteristic-equation]{characteristic equation} are \(1, 1, 3\) with \(1\) has \hyperref[def:multiplicity]{multiplicity} \(2\).
\end{explanation}

\begin{eg}
	Give an example of \(a\) where \(A\) defined as
	\[
		A = \begin{pmatrix}
			1 & 0 & 0 \\
			0 & 2 & 1 \\
			0 & a & 2 \\
		\end{pmatrix}
	\]
	has complex \hyperref[def:eigenvalue]{eigenvalues}.
\end{eg}
\begin{explanation}
	The \hyperref[note:characteristic-equation]{characteristic equation} of \(A\) is
	\[
		\begin{split}
			\det(\lambda I - A) &= \det \left(  \begin{pmatrix}
				\lambda - 1 & 0            & 0             \\
				0           & \lambda -  2 & -1            \\
				0           & -a           & \lambda -   2 \\
			\end{pmatrix}\right)\\
			&= (\lambda - 1)((\lambda - 2 )^2 - a)\\
			&= (\lambda - 1)(\lambda^2 - 4\lambda + 4 - a) = 0
		\end{split}
	\]
	Clearly, there is a root \(1\) for \(\lambda - 1 = 0\), as for the quadratic \(\lambda^2 - 4\lambda + (4 - a) = 0\), \(\vartriangle = 16 - 4(4-a) = 4a\). We see that for \(a = -1\), \(\vartriangle = -4 < 0 \implies\) the quadratic has complex roots. Hence,
	\[
		A = \begin{pmatrix}
			1 & 0  & 0 \\
			0 & 2  & 2 \\
			0 & -1 & 2 \\
		\end{pmatrix}
	\]
	has a complex \hyperref[def:eigenvalue]{eigenvalue}.
\end{explanation}

\section{Network Decomposition}\label{sec:network-decomposition}
Now comes to our main goal, i.e., to do the network decomposition. First, let's define a matrix which capture the \hyperref[def:graph]{graph} structure.
\begin{definition}[Laplacian]\label{def:Laplacian}
	For an \hyperref[def:undirected-graph]{undirected graph}, the \emph{Laplacian} is defined as \(L \coloneqq D - A\), where \(A\) is the \hyperref[def:adjacency-matrix]{adjacent matrix}, \(D\) is diagonal \hyperref[def:degree]{degree} matrix.
\end{definition}

\begin{remark}
	Since
	\[
		L^{\top} = (D - A)^{\top} = D^{\top} - A^{\top} = D - A = L,
	\]
	we see that \(L\) is \hyperref[def:symmetric-matrix]{symmetric}, hence its \hyperref[def:eigenvalue]{eigenvalues} are real by \autoref{thm:spectral-theorem}. Many incidence matrices \(B_{\left\vert \mathcal{V} \right\vert \times \left\vert \mathcal{E} \right\vert }\) which encode the relation between edges and nodes satisfies
	\[
		L = BB^{\top}.
	\]
	We'll show that \(L\) has non-negative \hyperref[def:eigenvalue]{eigenvalues} \hyperref[rmk:property-of-Laplacian]{later}.
\end{remark}
\subsection{Positive Definite and Positive Semi-Definite}
\begin{definition}[Positive definite]\label{def:positive-definite}
	\(A \) is \emph{positive definite} (PD) if and only if
	\[
		\forall \vec{x} \neq  \vec{0},\quad \vec{x}^{\top}A \vec{x} > 0.
	\]
\end{definition}

\begin{definition}[Positive semi-definite]\label{def:positive-semi-definite}
	\(A \) is \emph{positive semi-definite} (PSD) if and only if
	\[
		\forall \vec{x} \neq  \vec{0},\quad \vec{x}^{\top}A \vec{x} \geq  0.
	\]
\end{definition}

\begin{lemma}\label{lma:lec8-1}
	If \(\lambda\) is a real \hyperref[def:eigenvalue]{eigenvalue}, then \(\lambda \geq  0 \iff A\) is \hyperref[def:positive-semi-definite]{positive semi-definite}; also, \(\lambda > 0 \iff A\) is \hyperref[def:positive-definite]{positive-definite}.
\end{lemma}
\begin{proof}
	Suppose \(\lambda\) is a real \hyperref[def:eigenvalue]{eigenvalue}, let \(\vec{u}\) be the \hyperref[def:eigenvector]{eigenvector} such that \(A \vec{u} = \lambda \vec{u}\), and
	\[
		\vec{u}^{\top} A \vec{u} = \vec{u}^{\top} (\lambda \vec{u}) = \lambda \underbrace{\vec{u}^{\top}\vec{u}}_{>0} \geq 0,
	\]
	which implies \(A\) is \hyperref[def:positive-semi-definite]{positive semi-definite}. Similarly, if \(\lambda > 0 \implies \vec{u}^{\top} \vec{u} > 0\), \(A\) is \hyperref[def:positive-definite]{positive definite}. Lastly, the backward direction is obvious.
\end{proof}

\begin{lemma}\label{lma:lec8-2}
	\(A\) is \hyperref[def:positive-semi-definite]{positive semi-definite} and \hyperref[def:symmetric-matrix]{symmetric} \(\iff \exists \widetilde{B}\) such that \(A = \widetilde{B} \widetilde{B} ^{\top}\).
\end{lemma}
\begin{proof}
	We see that if \(A = \widetilde{B} \widetilde{B} ^{\top} \), it's clearly \hyperref[def:symmetric-matrix]{symmetric} and
	\[
		x^{\top} A x = x^{\top} \widetilde{B} \widetilde{B} ^{\top} x = (\widetilde{B} x)^{\top} \widetilde{B} x = y^{\top} y \geq 0,
	\]
	hence \(A\) is \hyperref[def:positive-semi-definite]{positive semi-definite}.

	For another direction, from \autoref{thm:spectral-theorem}, since \(A\) is \hyperref[def:symmetric-matrix]{symmetric}, we know that \(A = U D U^{\top}\) where all entries of \(D\) is \(\geq 0\) by \autoref{lma:lec8-1}. We see that we can decompose \(D\) into \(D = C C^{\top} \) where
	\[
		D = \begin{pmatrix}
			\lambda_1 &           &        &           \\
			          & \lambda_2 &        &           \\
			          &           & \ddots &           \\
			          &           &        & \lambda_n \\
		\end{pmatrix} = \begin{pmatrix}
			\sqrt{\lambda_1} &                  &        &                  \\
			                 & \sqrt{\lambda_2} &        &                  \\
			                 &                  & \ddots &                  \\
			                 &                  &        & \sqrt{\lambda_n} \\
		\end{pmatrix} \begin{pmatrix}
			\sqrt{\lambda_1} &                  &        &                  \\
			                 & \sqrt{\lambda_2} &        &                  \\
			                 &                  & \ddots &                  \\
			                 &                  &        & \sqrt{\lambda_n} \\
		\end{pmatrix} \eqqcolon C C^{\top},
	\]
	then by defining \(\widetilde{B} \coloneqq UC\), we see that
	\[
		A = U D U^{\top} = U C C^{\top} U^{\top} = (UC) (UC)^{\top} = \widetilde{B} \widetilde{B} ^{\top}
	\]
	as desired.
\end{proof}

\begin{remark}[Properties of Laplacian]\label{rmk:property-of-Laplacian}
	Given a Laplacian \(L = B B^{\top}\), from \autoref{lma:lec8-2}, \(L\) is \hyperref[def:positive-semi-definite]{positive semi-definite}, which further implies
	\[
		0 \leq \lambda_1 \leq \lambda_2 \leq \dots \leq \lambda_n.
	\]
	But \(\lambda_1 = 0\) since we have \(L = D-A\) where \(\diag(d_1, \dots , d_n)\) being the diagonal \hyperref[def:degree]{degree} matrix, and furthermore,
	\[
		L \vec{1} = (D - A)\vec{1} = \begin{pmatrix}
			d_1    \\
			d_2    \\
			\vdots \\
			d_n    \\
		\end{pmatrix} - A\vec{1} = \vec{0}
	\]
	since \(d_{i} = \sum_{j=1}^{n} A_{ij}\) from the \hyperref[def:adjacency-matrix]{definition} of \(A\), so
	\[
		L \vec{1} = 0 \vec{1}.
	\]
	Hence, \(0\) is an \hyperref[def:eigenvalue]{eigenvalue} with \hyperref[def:eigenvector]{eigenvector} \(\vec{1}\), so \(\lambda _1=0\).
\end{remark}

Now we study the \hyperref[def:multiplicity]{multiplicity} of an \hyperref[def:eigenvalue]{eigenvalue} of \(L\). We first introduce the following definition.
\begin{definition}[Multiplicity]\label{def:multiplicity}
	We say the \hyperref[def:eigenvalue]{eigenvalue} \(\lambda ^{\ast} \) of \(A\) has \emph{multiplicity} \(k\) if
	\[
		\det(\lambda I - A) = (\lambda - \lambda ^{\ast} )^k g(\lambda )
	\]
	where \(g(\cdot)\) is a polynomial in \(\lambda\) with \(g(\lambda ^{\ast} )\neq 0\).
\end{definition}

If the network has two \hyperref[def:connected]{connected} components, we can then relabel the nodes and obtain a concatenation of two \hyperref[def:adjacency-matrix]{adjacency matrices} that doesn't intersect
\[
	A = \begin{bmatrix}
		A_1 & 0   \\
		0   & A_2 \\
	\end{bmatrix}
\]
\begin{figure}[H]
	\centering
	\incfig{two-component-graph}
	\caption{Two \hyperref[def:connected]{connected} components \hyperref[def:graph]{graph}.}
	\label{fig:two-component-graph}
\end{figure}

Then we see that we can also represent the \hyperref[def:Laplacian]{Laplacian} in block matrix form as
\[
	L = \begin{bmatrix}
		D_{1} - A_{1} & 0         \\
		0             & D_2 - A_2 \\
	\end{bmatrix} \eqqcolon \begin{bmatrix}
		L_{1} & 0   \\
		0     & L_2 \\
	\end{bmatrix}.
\]
We then see that the \hyperref[note:characteristic-equation]{characteristic equation} of \(L\) is\footnote{Detailed derivation is omitted. It's essentially followed from the block structure.}
\[
	\det(\lambda I - L) = \det(\lambda I_1 - L_2)\det(\lambda  I_2 - L_2)
\]
Then, as we just \hyperref[rmk:property-of-Laplacian]{remarked}, both \(L_1\) and \(L_2\) has an \hyperref[def:eigenvalue]{eigenvalue} being \(0\), which implies that \(0\) is an \hyperref[def:eigenvalue]{eigenvalue} of \(L\) with \hyperref[def:multiplicity]{multiplicity} \(2\).

We see that \hyperref[def:multiplicity]{multiplicity} of \hyperref[def:eigenvalue]{eigenvalue} of \hyperref[def:Laplacian]{Laplacian} can help us find communities. This suggests the following definition.

\begin{definition}[Fiedler eigenvalue]\label{def:Filder-eigenvalue}
	The \emph{Fiedler \hyperref[def:eigenvalue]{eigenvalue}} of a \hyperref[def:graph]{graph} \(\mathcal{G}\) is the second-smallest eigenvalue (neglect \hyperref[def:multiplicity]{multiplicity}) of the \hyperref[def:Laplacian]{Laplacian} of \(\mathcal{G}\).
\end{definition}

We see that by first doing the \hyperref[thm:eigen-decomposition]{eigen-decomposition} on \hyperref[def:Laplacian]{Laplacian} and find all \hyperref[def:eigenvalue]{eigenvalues} that are close to zero, which can be used to find communities, and nearly all community detection algorithms rely on this fact.

\begin{prev}
	Turning back to \hyperref[algo:Girvan-Newman-algorithm]{Givran-Newman algorithm}, though it works at social network, but what about other tasks like internet?
	\begin{problem}
	Hyperlinks (directed): How important is the edge?
	\end{problem}
	\begin{answer}
		Internet search seems to rank nodes, not edges. (the website itself is the point?)
	\end{answer}

	An immediate question arises.

	\begin{problem}
	How does one rank nodes?
	\end{problem}
	\begin{answer}
		Network centrality.
	\end{answer}
\end{prev}
\begin{eg}[Network centrality]
	There are many examples of methods to quantify network centrality, e.g.,
	\begin{itemize}
		\item Degree. Ranks nodes by edges.
		\item Eigen-centrality. \hyperref[def:adjacency-matrix]{Adjacency matrix}, finds an \hyperref[def:eigenvector]{eigenvector} and use its entries.
	\end{itemize}
\end{eg}

We now study this in depth.

\chapter{Page Rank}
In this chapter, we still try to analyze a given network, but now we're focusing on nodes-importance rather than links-importance. Our goal is to develop the so-called \textbf{page rank}, which is inspired by the following algorithm.

\section{HITS Algorithm}
\hyperref[algo:HITS-algorithm]{HITS} is a hyperlinks-induced topic search algorithm proposed by \href{https://en.wikipedia.org/wiki/Jon_Kleinberg}{John Kleinberg}, whose backbones are the idea of \textbf{hubs} and \textbf{authorities} and the \textbf{voting mechanism}.
\begin{itemize}
	\item Hubs: nodes that \emph{aggregate}.
	\item Authorities: nodes that are \emph{important}.
\end{itemize}

The key idea is that
\begin{enumerate}
	\item If many websites (nodes) point to it, then this website is important (authority property).
	\item If a node points to many authority nodes, then it is important as well.
\end{enumerate}
Then by iteratively identifying hubs and authorities, we can rank the nodes in the network. We now describe in detailed how this algorithm works. We first see the pseudocode of the \hyperref[algo:HITS-algorithm]{algorithm}.

\begin{algorithm}[H]\label{algo:HITS-algorithm}
	\DontPrintSemicolon{}
	\caption{HITS Algorithm}
	\SetKwData{h}{hub}
	\SetKwData{a}{auth}
	\KwData{A network \(\mathcal{G} = (\mathcal{V} , \mathcal{E} ) \)}
	\KwResult{\(\h\), \(\a\)}

	\BlankLine

	\For(\Comment*[f]{Initialize}){\(v\in \mathcal{V} \)}{
		\(\a(v)\gets 1\)\;
		\(\h(v)\gets 1\)\;
	}
	\;
	\While{not converge}{
		\For(\Comment*[f]{\a update}){\(v\in \mathcal{V}\)}{
			\(\a(v) \gets \sum_{u\in \mathcal{V} \colon u\to v\in \mathcal{E}} \h(u)\)\;
		}
		\For(\Comment*[f]{\h update}){\(v\in \mathcal{V}\)}{
			\(\h(v) \gets \sum_{u\in \mathcal{V} \colon v\to u\in \mathcal{E}} \a(u)\)\;
		}
		\;
		\For(\Comment*[f]{\a normalize}){\(v\in \mathcal{V}\)}{
			\(\a(v) \gets \a(v) / \sum_{u\in \mathcal{V} } \a(u) \)\;
		}
		\For(\Comment*[f]{\h normalize}){\(v\in \mathcal{V}\)}{
			\(\h(v) \gets \h(v) / \sum_{u\in \mathcal{V}} \h(u)\)\;
		}
	}
	\Return{\(\h\), \(\a\)}\;
\end{algorithm}

\begin{note}
	There are two facts are worth noting.
	\begin{enumerate}
		\item \(\mathtt{hub(\mathnormal{v})}\) and \(\mathtt{auth(\mathnormal{v})}\) will converge as long as initial score are positive.
		\item Final scores will be independent of the initial scores.
	\end{enumerate}
\end{note}
