\lecture{4}{12 Sep.\ 10:30}{Feedback Vertex Set}
\section{Feedback Vertex Set}
Following the discussion on primal-dual method, we see another \hyperref[def:covering]{covering} problem.

\subsection{Introduction}
We consider the following problem.

\begin{problem}[Feedback vertex set]\label{prb:feedback-vertex-set}
Given a graph \(\mathcal{G} = (\mathcal{V} , \mathcal{E} )\) and a weight function \(c\colon \mathcal{V} \to \mathbb{R} ^+\), we want to find \(F\subseteq \mathcal{V} \) with \(\min c(F)\) such that \(\mathcal{G} [\mathcal{V} \setminus F]\) has no cycle.\footnote{This is equivalent as saying that \(\mathcal{G} [\mathcal{V} \setminus F]\) is a forest.}
\end{problem}

\begin{note}[Feedback]
	The name \emph{feedback} comes from the fact that if there's a cycle in \(\mathcal{G} \), then it kind of creates \emph{feedback}.
\end{note}

\begin{note}[Edge version]
	The \emph{edge version} of \autoref{prb:feedback-vertex-set} can be solved by finding \(T\subseteq \mathcal{E} \) be the maximum weight forest,\footnote{This can be found exactly in polynomial time.} and let \(F \coloneqq \mathcal{E} \setminus T\).
\end{note}

\begin{notation}
	In this lecture, when talking about cycle, we're referring to the vertices in which. But the meaning can vary from context to context.
\end{notation}

\begin{remark}
	This is a \emph{special case} of \autoref{prb:set-cover}.
\end{remark}
\begin{explanation}
	Let \(\mathcal{C} \coloneqq \left\{ \text{set of all (simple) cycles}  \right\}\) and consider \autoref{prb:set-cover} on the set system \((\mathcal{C} , \mathcal{V} )\), i.e., we want to find \(F\subseteq \mathcal{V} \) such that \(\forall C\in \mathcal{C} \), \(\left\vert F \cap C \right\vert \geq 1\).
\end{explanation}

\begin{note}
	The naive algorithm by directly applying methods discussed for \autoref{prb:set-cover}, we see that since \(\min (\log k, d) = \Omega (n)\) for \(k\) being the maximum set size (which is \(2^{\Omega (n)}\)) and \(d = n\), the approximation ratio we can get is \(\Omega (n)\), which depends on the size of the input.
\end{note}

Now, the goal in this section is to show the following.
\begin{theorem}\label{thm:feedback-vertex-set}
	There exists a \(4\)-approximation algorithm for \autoref{prb:feedback-vertex-set}.
\end{theorem}

\begin{remark}
	Actually, there exists a \(2\)-approximation algorithm.
\end{remark}

We also have a hardness of \autoref{prb:feedback-vertex-set}.
\begin{theorem}\label{thm:feed-back-vertex-set-hardness}
	Achieving \((2 - \epsilon )\)-approximation algorithm if \(\NP\)-hard for all \(\epsilon > 0\) assuming the \hyperref[conj:unique-game]{unique games conjecture}.
\end{theorem}
\begin{proof}
	See Homework \(1\).
\end{proof}

\subsection{Cycle Covering LP}\label{subsec:cycle-covering-LP}
The most natural LP which models \autoref{prb:feedback-vertex-set} is the so-called \emph{cycle covering LP}, which can be defined as
\[
	\begin{aligned}
		\min~ & \sum_{v\in \mathcal{V} } c(v) x_v                                                               \\
		      & \sum_{v\in C} x_v \geq 1                         \quad \forall \text{ cycle } C \in \mathcal{C} \\
		      & x \geq 0,
	\end{aligned}
\]
with the variables being \(\left\{ x_v \right\} _{v\in \mathcal{V} }\) such that \(x_{v} = \mathbbm{1}_{v\in F}\).

\begin{remark}
	We see that this cycle covering LP has \(2^{\Omega (n)}\) constraints. But we can actually solve this and get an \(O(\log n)\)-approximation ratio by smartly rounding the solution.\footnote{See homework \(1\).} And we can show that this approximation ratio is optimal in terms of this particular LP.
\end{remark}

\subsection{Density LP}
A more sophisticated LP is the so-called \emph{density LP}, defined as
\[
	\begin{aligned}
		\min~ & \sum_{v\in \mathcal{V} } c(v) x_v                                                                                                  \\
		      & \sum_{v\in S} x_v(d_v^{S} - 1) \geq \left\vert E(S) \right\vert - \left\vert S \right\vert + 1\quad \forall S\subseteq \mathcal{V} \\
		      & x\geq 0
	\end{aligned}
\]
with the variables being \(\left\{ x_v \right\} _{v\in \mathcal{V} }\).

\begin{notation}
	The \(E(S)\) denotes the edge set in the induced graph \(\mathcal{G} [S] = (S, E(S))\), while \(d_v^S\) denotes the degree of \(v\) in \(\mathcal{G} [S]\).
\end{notation}

\begin{intuition}
	The constraint is equivalent as  saying that for every induced graph, \(\# e \leq \# v - 1\), i.e., we require it to be a forest. Explicitly, \(S\subseteq \mathcal{V} \),
	\[
		\left\vert E(S) \right\vert - \sum_{v\in S} x_v d_v^S\leq \left\vert S \right\vert - \sum_{v\in S}x_v - 1.
	\]
	Note that in the constraint, the right-hand side is just a lower-bound of \(\# e\).
\end{intuition}

We see that the above LP is not exactly a \hyperref[def:covering-LP]{covering LP} since the coefficients can be negative if a set \(S\) is not \hyperref[def:irreducible]{irreducible}.

\begin{definition}[Irreducible]\label{def:irreducible}
	The set \(S\subseteq \mathcal{V} \) is \emph{irreducible} if for all \(v\in S\), \(v\) belongs to some cycles in \(G[S]\).
\end{definition}

Now, it's clear that by looking at \(\mathcal{S} = \left\{ S\subseteq \mathcal{V} \mid S \text{ is \hyperref[def:irreducible]{irreducible}}\right\} \), we have a \hyperref[def:covering-LP]{covering LP} defined as
\[
	\begin{aligned}
		\min~ & \sum_{v\in \mathcal{V} } c(v) x_v                                                                                                          \\
		      & \sum_{v\in S} x_v(d_v^{S} - 1) \geq \left\vert E(S) \right\vert - \left\vert S \right\vert + 1 \eqqcolon b_S\quad \forall S\in \mathcal{S} \\
		      & x\geq 0.
	\end{aligned}
\]

We first see why this LP models \autoref{prb:feedback-vertex-set}.

\begin{lemma}\label{lma:feedback-vertex-set-1}
	The integer version of density LP (denote as IP) is equivalent to \autoref{prb:feedback-vertex-set}.
\end{lemma}
\begin{proof}
	If \(x\) is feasible for \autoref{prb:feedback-vertex-set}, then \(x\) is feasible for the IP. On the other hand, if \(x\) is feasible for IP, then for every cycle \(C\in \mathcal{C} \), \(x\) deletes at least \(1\) vertex from \(C\).
\end{proof}

\subsection{Primal-Dual Method}
Now we're ready to solve this LP via primal-dual method. Denote the dual variables as \(\left\{ y_S \right\} _{S\in \mathcal{S} }\), then the dual is
\[
	\begin{aligned}
		\max~ & \sum_{S\in \mathcal{S} } y_S b_S                                       \\
		      & \sum_{S\ni v}(d_{v} ^S - 1)y_S \leq c(v)\quad \forall v\in \mathcal{V} \\
		      & y\geq 0.
	\end{aligned}
\]

\begin{note}
	For the density LP and its dual, the constraint is still exponentially many, and no one knows how to solve this. But the power of primal-dual method is that we don't really solve this, rather, we just maintain two sets of solutions for both primal and dual. Moreover, we can maintain the primal solution in integral, while the dual solution in fractional.
\end{note}

We now have the following algorithm.

\begin{algorithm}[H]\label{algo:feedback-vertex-set-PD}
	\DontPrintSemicolon{}
	\caption{\hyperref[prb:feedback-vertex-set]{Feedback vertex set} -- Primal-Dual}
	\KwData{A graph \(\mathcal{G} =(\mathcal{V} , \mathcal{E} )\)}
	\KwResult{A minimal \hyperref[prb:feedback-vertex-set]{feedback vertex set} \(F^\prime \)}
	\SetKwFunction{reduce}{reduce}
	\BlankLine

	\(S\gets \mathcal{V} \), \(c^\prime = c\), \(y\gets 0\)\Comment*[r]{\(c^\prime \in \mathbb{R} ^n\) keeps track of slackness of \(c\)}
	\;
	\While(){\(S \neq \varnothing \)}{
		\(S\gets\) \reduce{\(S\) }\Comment*[r]{Compute \(\left\{ v\in S\colon v\text{ belongs to some cycles in }\mathcal{G} [S]\right\}\)}
		\((\alpha, v) \gets \min _{v\in S} c^\prime (v) / (d_v^S - 1)\)\footnote{Note that we also get the argument \(v\).}\Comment*[r]{\(y_S\) gets tight by increasing unit weight}
		\(y_S\gets \alpha\)\label{algo:feedback-vertex-set-PD:line6}\;
		\(c^\prime (v)\gets c^\prime (v) - \alpha (d_v^S - 1)\)\label{algo:feedback-vertex-set-PD:line7}\;
		\(Z\gets \left\{ v\in S\colon c^\prime (v) = 0 \right\} \)\;
		\(F\gets F\cup Z\), \(S\gets S \setminus Z\)\;
	}
	\;
	\Comment{Compute a minimal \hyperref[prb:feedback-vertex-set]{feedback vertex set}}
	\(F^\prime \gets F = \left\{ v_1, \dots , v_{\ell} \right\} \)\Comment*[r]{\(v_1\) is deleted first, \(v_{\ell}\) is deleted last}
	\For(\label{algo:feedback-vertex-set-PD:for}\Comment*[f]{\hyperref[rmk:reversed-greedy]{reversed greedy}}){\(i = \ell , \dots  , 1\)}{
		\If(){\(F^\prime \setminus \left\{ v_i \right\}\) is a \hyperref[prb:feedback-vertex-set]{feedback vertex set} for \(\mathcal{G} \)}{
			\(F^\prime \gets F^\prime \setminus \left\{ v_i \right\} \)\;
		}
	}
	\Return{\(F^\prime \)}\;
\end{algorithm}

We see that in \autoref{algo:feedback-vertex-set-PD}, we first use primal-dual method to obtain a feasible \hyperref[prb:feedback-vertex-set]{feedback vertex set}, and then run a \hyperref[rmk:reversed-greedy]{reversed greedy} algorithm to further ensure we get a good approximation ratio.

\begin{claim}
	\(F\) is a \hyperref[prb:feedback-vertex-set]{feedback vertex set} and \(y\) is dual-feasible.
\end{claim}
\begin{explanation}
	It should be clear that why \(F\) is a \hyperref[prb:feedback-vertex-set]{feedback vertex set}. As for the reason why \(y\) is dual-feasible, observe that we have one constraint for each \(v\). After raising \(y_S\) for chosen \(v\) in \autoref{algo:feedback-vertex-set-PD:line6} and deduce \(c^\prime (v)\) in \autoref{algo:feedback-vertex-set-PD:line7}, \(v\) will get removed so the constraint corresponding to \(v\) will be satisfied throughout.
\end{explanation}

\begin{remark}[Reversed greedy]\label{rmk:reversed-greedy}
	The method we turn \(F\) into its minimal is called \emph{reversed greedy}. This just checks that if we remove a vertex \(v\) from \(F^\prime \) while \(F^\prime \) is still feasible, then we just do it. Additionally, we iterate through \(v\) in the \textbf{reversed} order w.r.t.\ how \(v\) is being added into.
\end{remark}

We want to compare the primal cost and the dual cost. The primal cost is
\[
	c(F) = \sum_{v\in F}c(v) = \sum_{v\in F}\sum_{S\ni v} (d_{v} ^S - 1) y_S = \sum_{S\in \mathcal{S}}y_S \sum_{v\in F \cap S}(d_{v} ^S - 1),
\]
while the dual cost is \(\sum_{S\in \mathcal{S} }y_S b_S\).

\begin{remark}
	This is where the primal-dual method is powerful. i.e., by switching the order of summation, if we have some ratio of \(\sum_{v\in F \cap S}(d_{v} ^S - 1)\) and \(b_S\) for every \(S\), we're done. On caveat is that since \(S\) is changing when running \autoref{algo:feedback-vertex-set-PD}, so the final solution \(F\) may not be good for this particular \(S\). We need to guarantee some ratio for this \(F\) \textbf{for all \(S\)}.\footnote{At least for \(S\) with positive \(y_S\).}
\end{remark}

\begin{lemma}\label{lma:feedback-vertex-set-2}
	For all \(S\in \mathcal{S} \), if \(F\) is \emph{minimal} in \(S\),\footnote{i.e., in \(\mathcal{G} [S]\), no \(F^\prime \subsetneq F \cap S\) in \hyperref[prb:feedback-vertex-set]{feedback vertex set}.} then we have
	\[
		\sum_{v\in S \cap F}(d_{v} ^S - 1) \leq 4\cdot b_S = 4(\left\vert E(S) \right\vert - \left\vert S \right\vert + 1).
	\]
\end{lemma}
\begin{proof}
	Let's first see a simple case.
	\begin{intuition}
		If the graph is \(3\)-regular, then we see that the left-hand side is \(\leq 2\cdot \left\vert S \right\vert \) by summing over the whole \(S\) instead of \(S\cap F\), while the right-hand side is \(2\cdot \left\vert S \right\vert + 4\) since \(\left\vert E(S) \right\vert = 1.5 \left\vert S \right\vert \).

		This shows that in a \(3\)-regular graph, deleting every vertex in \(S\) is actually \(4\)-approximated. And this intuition generalized to general graph with degree greater than \(3\).
	\end{intuition}

	Since we assume \(S\) to be \hyperref[def:irreducible]{irreducible}, so we're not interested in degree \(0\) or \(1\) vertices (there are no such vertices in an \hyperref[def:irreducible]{irreducible} \(S\)). So the only problematic guy is degree-\(2\) vertex. And the only place a degree-\(2\) vertex can live is in a long path.

	\begin{figure}[H]
		\centering
		\incfig{FBV-path}
		\caption{If there are two \(v\in F\), by minimality of \(F\), one of \(v\) will be strictly unnecessary to break this path in a cycle.}
		\label{fig:FBV-path}
	\end{figure}
	\begin{note}
		Observe that we only need to delete at most one vertex in any path, and sometimes this may be loose since we can delete one branch node joining two paths, i.e., deleting \(1\) nodes for two paths.
	\end{note}

	Let \(A\) be the set of degree \(2\) vertices, and \(B\) be the set of vertices with degree larger than \(3\). Now, consider line segment in the graph. If \(\ell \) is a line segment,
	\begin{enumerate}[(a)]
		\item \(\left\vert F \cap  \ell  \right\vert \leq 1\), i.e., we delete at most one point in \(\ell \).
		\item If \(F\) contains one of the endpoints of \(\ell \), then \(\left\vert F \cap \ell  \right\vert = 0\).
	\end{enumerate}

	Since \(F\) is minimal, the left-hand side is
	\[
		\left\vert A \cap  F \right\vert + \sum_{v\in B \cap F}(d_{v} ^S - 1) \leq \sum_{v\in B \setminus F} d_{v} ^S / 2 + \sum_{v\in B \cap F}(d_{v} ^S - 1) \leq \sum_{v\in B}(d_{v}^S - 1 ),
	\]
	where the first inequality comes from the fact that if we delete vertices in \(A\), i.e., in the line segment, then we know we don't delete its end points, and by \emph{distributed} that \(1\) cost into its two end points, each \(1 / 2\).
	\begin{figure}[H]
		\centering
		\incfig{FBV-line-segment}
		\caption{Distribute the cost of \(F\).}
		\label{fig:FBV-line-segment}
	\end{figure}
	Similarly, in the right-hand side, the crucial term is
	\[
		\left\vert E(S) \right\vert - \left\vert S \right\vert = \sum_{v\in S}(d_{v} ^S / 2 - 1) = \sum_{v\in B} (d_{v} ^S / 2 - 1)
	\]
	where the last equality holds since for \(v\in A\), the summand is just \(2 / 2 - 1 = 0\). It's clear that since \(\forall v\in B\), \(d_v^S - 1 \leq 4 (d_{v} ^S / 2 - 1)\), rearranging this inequality gives the result.
\end{proof}

To show \autoref{thm:feedback-vertex-set}, it's enough to have a minimal \(F\), then the result follows form \autoref{lma:feedback-vertex-set-1}. Hence, after obtaining \(F\), \autoref{algo:feedback-vertex-set-PD} further convert \(F\) into \(F^\prime \) and  try to obtain a minimal version of \(F\). Clearly, \(F^\prime \) is still a \hyperref[prb:feedback-vertex-set]{feedback vertex set}, and the minimality of \(F^\prime \) is guaranteed by the following lemma.

\begin{lemma}\label{lma:feedback-vertex-set-3}
	\(F^\prime \) is minimal in every \(S_i\), where \(S_i\) is the corresponding \(S\) in \autoref{algo:feedback-vertex-set-PD} when \(v_i\) is deleted.
\end{lemma}
\begin{proof}
	Suppose this is not the case. Then there exists \(v_j\in F^\prime \) such that in \(\mathcal{G} [S_i]\), \((F \cap S_i) \setminus \left\{ v_{j}  \right\}\) is still a \hyperref[prb:feedback-vertex-set]{feedback vertex set} in \(\mathcal{G} [S_j]\). Notice that we only need to consider the case that \(i = j\) since \(v_{j}\in S_i\) means \(i \geq j\) from how we order them. In this case, \(S_j \subseteq S_i\), hence to check the minimality of \(F^\prime \) it's enough to just consider the case that \(i = j\). Hence, we consider \((F \cap S_j) \setminus \left\{ v_{j}  \right\}\) instead.

	\begin{note}
		Here we only consider \(G[S_j]\), i.e., we want to say that if \(v_j\) is not minimal in \(G[S_j]\), then \(v_j\) should really be deleted even w.r.t.\ the whole graph.
	\end{note}

	Now, observe the following picture in step \(j\) of \autoref{algo:feedback-vertex-set-PD:for} with cycles contained \(v_j\):
	\begin{figure}[H]
		\centering
		\incfig{FBV-minimality}
	\end{figure}

	Observe that the middle cycles in \(G[S_j]\) must exist from our assumption of \((F \cap S_j) \setminus \left\{ v_{j}  \right\}\) being still a \hyperref[prb:feedback-vertex-set]{feedback vertex set}, i.e., if a cycle exists in \(G[S_j]\), then it must contain another nodes other than \(v_j\) that's also in \(F^\prime \). But we see that when we consider cycles outside \(G[S_j]\), we have the following.
	\begin{claim}
		No vertices outside \(S_j\) which is also in \(F\setminus F^\prime \) at step \(j\) of \autoref{algo:feedback-vertex-set-PD:for}
	\end{claim}
	\begin{explanation}
		Since \(S_j\) is growing, i.e., for \(i \leq j\), \(S_i \leq S_j\), and we just can't delete something we haven't considered.
	\end{explanation}

	\begin{claim}
		There are no cycles \(C\ni v_j\) such that \(C\setminus S_j\) is disjoint from \(F\).
	\end{claim}
	\begin{explanation}
		Observe that there are only two ways for a vertex being deleted from the graph, either \(v\in Z\), i.e., its dual constraint is tight, or \(v\in S\) is deleted since it prevent \(S\) being \hyperref[def:irreducible]{irreducible}. Only the latter case will make \(v \notin F\), we see that there's no way such a cycle \(C\) exists with all vertices outside \(S_j\) are preventing \(s\) being \hyperref[def:irreducible]{irreducible}, since this cycle \(C\) itself is a cycle...
	\end{explanation}

	This implies \(F^\prime \setminus \left\{ v_j \right\} \) is still a \hyperref[prb:feedback-vertex-set]{feedback vertex set} in \(\mathcal{G} \) when \(i = j\) in \autoref{algo:feedback-vertex-set-PD} since such a problematic cycle can't exist,\footnote{Explicitly, if this exists, then delete \(v_j\) will make \(F^\prime\) fail to intersect such a cycle.} which contradicts with the minimality of \(F^\prime\).
\end{proof}

Finally, we see that we can prove \autoref{thm:feedback-vertex-set}.

\begin{proof}[Proof of \autoref{thm:feedback-vertex-set}]
	Firstly, \autoref{algo:feedback-vertex-set-PD} gives a \(4\)-approximation of the density IP guaranteed by \autoref{lma:feedback-vertex-set-2} and \autoref{lma:feedback-vertex-set-3}. Finally, from \autoref{lma:feedback-vertex-set-1}, we see that \autoref{prb:feedback-vertex-set} and the density IP is equivalent, proving the theorem.
\end{proof}