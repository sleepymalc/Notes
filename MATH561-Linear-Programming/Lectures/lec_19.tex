\lecture{19}{10 Nov.\ 8:00}{Lagrangian Relaxation}
\begin{prev}
	We have
	\[
		\begin{aligned}
			z\coloneqq \min~ & c^{\top}x \\
			                 & Ex \geq h \\
			                 & Ax = b    \\
			(Q)\quad         & x\geq 0
		\end{aligned}
	\]
	and by choosing \(\hat{y}\geq \vec{0}\), we have the \hyperref[def:Lagrangian-subproblem]{Lagrangian subproblem}
	\[
		\begin{aligned}
			v(\hat{y})\coloneqq \hat{y}^{\top}h + \min~ & (c^{\top} - \hat{y}^{\top}E)x \\
			                                            & Ax = b                        \\
			(L_{\hat{y}})\quad                          & x\geq 0.
		\end{aligned}
	\]
\end{prev}

Now, we introduce another problem.

\begin{definition}[Lagrangian dual]\label{def:Lagrangian-dual}
	The \emph{Lagrangian dual} problem is defined as
	\[
		\max_{y\geq \vec{0}}\ v(y).
	\]
\end{definition}

\begin{note}
	We see that for \(\hat{y}\geq \vec{0}\), \(v(\hat{y})\leq z\). Now, the goal is to solve the \hyperref[def:Lagrangian-dual]{Lagrangian dual} to get a lower bound for the original problem. (Notice that this is the maximum of the \hyperref[def:dual]{dual}!)
\end{note}

Now, we try to proof \autoref{thm:converse-Lagrangian-dual}, which is the \emph{partial} converse of \autoref{thm:Lagrangian-dual}.

\begin{proof}[Proof of \autoref{thm:converse-Lagrangian-dual}]
	Recall that
	\[
		\begin{split}
			v(\hat{y}) & \coloneqq \max_{y\geq \vec{0}}\ v(y)                                                                                                                                      \\
			           & = \max_{y\geq \vec{0}} \Bigg\{y^{\top}h + \underbrace{\min_{x}\ \left\{(c^{\top} - y^{\top}E)x\colon Ax = b, x\geq \vec{0}\right\}}_{\text{just a linear program}}\Bigg\} \\
			           & = \max_{y\geq \vec{0}}\ \left\{y^{\top}h + \max_{\Pi}\ \left\{\Pi^{\top}b\colon \Pi^{\top}A\leq c^{\top} - y^{\top}E\right\}\right\}                                      \\
			           & = \max_{y\geq \vec{0}, \Pi}\ \left\{y^{\top}h + \Pi^{\top}b\colon \Pi^{\top}A + y^{\top}E\leq c^{\top}\right\}                                                            \\
			           & = z.
		\end{split}
	\]
	The last equality is derived from the fact that it's just the \hyperref[def:dual]{dual} of the \(Q\).
\end{proof}

\subsection{Solving the Lagrangian Dual}
\begin{intuition}
	\autoref{thm:converse-Lagrangian-dual} provides a simple way to calculate a lower bound on \(z\) by solving a potentially easier linear optimization problem. But we see that the bound depends on the choice of \(\hat{y}\geq 0\). This push us to find the best such \(\hat{y}\), and we indeed can solve this by solving the so-called \hyperref[def:Lagrangian-dual]{Lagrangian dual} problem of \emph{maximizing} \(v(y)\) over all \(y\geq 0\) in the domain of \(v\).
\end{intuition}

One may want to use some calculus technique to solve for such maximizing problem, but since \(v\) is not a smooth function, rather a piece-wise linear function, hence we need to introduce the concept of \hyperref[def:subgradient]{subgradient}. Before we formally introduce it, we first see a theorem.

\begin{theorem}\label{thm:lec19-1}
	Suppose we fix \(\hat{y}\geq \vec{0}\) and solve for \(v(\hat{y})\). Let \(\hat{x}\) be the \hyperref[def:optimal-solution]{optimal solution} of \(L_{\hat{y}}\). Denote \(\hat{\gamma}\coloneqq h - E \hat{x}\), then
	\[
		v(\widetilde{y})\leq v(\hat{y})+(\widetilde{y} - \hat{y})\hat{\gamma}
	\]
	for all \(\widetilde{y}\) in the domain of \(v\).
	\begin{center}
		\incfig{subgradient-theorem}
	\end{center}
\end{theorem}

\begin{proof}
	We see that since
	\[
		\begin{split}
			v(\hat{y})+(\hat{y} - \widetilde{y})\hat{\gamma} & =v(\hat{y})+(\hat{y} - \widetilde{y})(h - E \hat{x})                                                      \\
			                                                 & = \hat{y}^{\top}h + (c^{\top} - \hat{y}^{\top}E)\hat{x} + (\widetilde{y} - \hat{y})^{\top}(h - E \hat{x}) \\
			                                                 & = \widetilde{y}^{\top}h + (c^{\top} - \widetilde{y}^{\top} E)\hat{x}                                      \\
			                                                 & \geq v(\widetilde{y}).
		\end{split}
	\]
	The last inequality follows from the fact that \(\hat{x}\) is only \hyperref[def:optimal-solution]{optimal} for \(L_{\hat{y}}\), not \(L_{\widetilde{y}}\). \(\hat{x}\) may just be \hyperref[def:feasible-solution]{feasible} for \(L_{\hat{y}}\).
\end{proof}

In the theorem, \(\hat{\gamma}\) is the so-called \hyperref[def:subgradient]{subgradient}. Given \(\widetilde{y}\) and \(\hat{y}\), we choose \(\hat{\gamma}\) such that the linear estimation \(v(\hat{y})+(\widetilde{y} - \hat{y})^{\top}\hat{\gamma}\) is always an upper bound on the value \(v(\widetilde{y})\) of the function for all \(\widetilde{y}\) in the domain of \(f\). This \(\hat{\gamma}\) is then a \hyperref[def:subgradient]{subgradient} of (the \hyperref[def:convex-function]{concave function}\footnote{Contrast to \autoref{def:convex-function}.}) \(v\) at \(\hat{y}\).

Mathematically, we have the following.

\begin{definition}[Subgradient]\label{def:subgradient}
	For a \hyperref[def:convex-function]{concave function} \(f\colon I\to \mathbb{R}\), the \emph{subgradient} (also known as \emph{subderivative}) at point \(x_0\) is a \(c\in \mathbb{R}\) such that
	\[
		f(x) - f(x_{0})\geq c(x - x_0)
	\]
	for every \(x\in I\).
\end{definition}

With this \autoref{thm:lec19-1} about \hyperref[def:subgradient]{subgradient}, we can then develop an algorithm to utilize this.

\subsection{Projected Subgradient Optimization Algorithm}
\begin{intuition}
	We iteratively move in the direction of a \hyperref[def:subgradient]{subgradient} to maximize \(v\).
\end{intuition}

\begin{algorithm}[H]\label{algo:projected-subgradient-optimization-algorithm}
	\DontPrintSemicolon{}
	\caption{Projected subgradient optimization algorithm}
	\KwData{\hyperref[def:objective-function]{Objective function} of \hyperref[def:Lagrangian-dual]{Lagrangian dual} \(v(\hat{y}) = \hat{y} ^{\top} h + \min (c^{\top} -\hat{y} ^\top E)x\), maximum iteration \(K\)}
	\KwResult{Estimated maximum value of \(v(\hat{y})\)}
	\BlankLine

	Initialize a random \(\mathbb{R} ^m\) vector \(\hat{y}^{\top}\geq \vec{0}\)\;
	\For(){\(k = 1, \dots K\)}{
		Solve \(L_{\hat{y}^k}\) to get \(\hat{x}^k\)\;
		\(\hat{\gamma}^k \gets h - E \hat{x}^k\)\;
		\(\hat{y}^{k+1} \gets \Proj_{\mathbb{R}^m_+}(\hat{y}^k + \lambda_{k}\hat{\gamma}^k) \)\;\label{algo:projected-subgradient-optimization-algorithm:line5}
	}
	\Return{\(v(\hat{y} ^{K})\)}\;
\end{algorithm}

\begin{remark}
	There are a few remarks we want to make.
	\begin{itemize}
		\item The projection \(\Proj_{\mathbb{R}^m_+}\) is just used to set any negative entries equal to \(0\).
		\item The key is in the \autoref{algo:projected-subgradient-optimization-algorithm:line5}. We want to choose \(\lambda_{k}>0\) and satisfying something, which will make this algorithm converges.
		      \begin{itemize}
			      \item \textbf{Harmonic step size}: Define the step size as \(\lambda_{k}\coloneqq \frac{1}{k}\), which will converge in theory, but it is slow. Notice that this choice of step size is \emph{independent} of the current value of the subgradient.
			      \item \textbf{Polyak step size}: Define the step size as
			            \[
				            \lambda_{k}\coloneqq \frac{\mathrm{GUESS} - v}{\left\lVert \hat{\gamma}^k\right\rVert^2 },
			            \]
			            where we need an initial \(\mathrm{GUESS}\) (we get this by literally \emph{guessing}) to let the algorithm behaves reasonable.
		      \end{itemize}
	\end{itemize}
\end{remark}