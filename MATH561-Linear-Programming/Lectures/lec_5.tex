\lecture{5}{15 Sep. 08:00}{Convex Set and Extreme Points}
\subsection{Convex Sets}
We now turn our focus to the geometry of the \hyperref[def:general-linear-programming-problem]{linear program}. Let's first study perhaps one of the most important class of sets, the \hyperref[def:convex-set]{convex sets}.

\begin{definition}[Convex set]\label{def:convex-set}
	A set \(S\subseteq \mathbb{R}^n\) is \emph{convex} if for any \(x^1, x^2\in S\) and \(0 < \lambda < 1\),
	\[
		\lambda x^1 + (1-\lambda)x^2 \in S.
	\]
\end{definition}

\begin{figure}[H]
	\centering
	\incfig{convex-set}
	\caption{The first two are \hyperref[def:convex-set]{convex sets}, while the latter two are not since (some parts of) those red lines are outside the set.}
	\label{fig:convex-set}
\end{figure}

\begin{intuition}
	A \hyperref[def:convex-set]{convex set} is a set that contains every line segment between two points in which.
\end{intuition}

\begin{remark}
	The \hyperref[def:feasible-region]{feasible region} \(S\) of any \hyperref[def:general-linear-programming-problem]{linear program} is a \hyperref[def:convex-set]{convex set}.
\end{remark}
\begin{explanation}
	Consider a \hyperref[def:standard-form]{standard form} problem, and suppose there are two \hyperref[def:feasible-solution]{feasible} points \(x^1\) and \(x^2\in S\). Then
	\[
		\begin{dcases}
			Ax^1 = b, & x^1\geq 0 ; \\
			Ax^2 = b, & x^2\geq 0 . \\
		\end{dcases}
	\]
	This implies
	\[
		A\underbrace{(\lambda x^1 + (1-\lambda)x^2)}_{\geq 0}
		= \lambda A x^1 + (1-\lambda)A x^2
		= (\lambda + (1-\lambda))b
		= b
	\]
	for every \(\lambda \in (0,1)\). With the fact that \(\lambda x^1 + (1-\lambda)x^2\) is non-negative, hence it's \hyperref[def:feasible-solution]{feasible}.
\end{explanation}

\subsection{Extreme Points}
Now, the importance of \hyperref[def:convex-set]{convex sets} is illustrated via the following notion.

\begin{definition}[Extreme point]\label{def:extreme-point}
	Suppose \(S\) is a \hyperref[def:convex-set]{convex set}, then \(\hat{x} \in S\) is an \emph{extreme point} of \(S\) if we \textbf{cannot} write
	\[
		\hat{x} = \lambda x^1 + (1-\lambda)x^2
	\]
	with \(x^1 \neq x^2\), \(x^1, x^2\in S\), \(0<\lambda<1\).
\end{definition}

Then we have an important theorem.

\begin{theorem}\label{thm:lec5-1}
	Every \hyperref[def:basic-solution]{basic} \hyperref[def:feasible-solution]{feasible} solution of \hyperref[def:standard-form]{standard form} problem \((\mathrm{P})\) is an
	\hyperref[def:extreme-point]{extreme point} of the \hyperref[def:feasible-region]{feasible region} of \((\mathrm{P})\).
\end{theorem}
\begin{proof}
	Consider a \hyperref[def:basic-solution]{basic} \hyperref[def:feasible-solution]{feasible} solution \(\overline{x}\colon \overline{x}_{\eta} = \vec{0}\),
	\(\overline{x}_{\beta} = A^{-1}_{\beta}b\geq \vec{0}\). If it is not an \hyperref[def:extreme-point]{extreme point}, then we have
	\[
		\exists x^1\neq x^2 \text{ which is \hyperref[def:feasible-solution]{feasible}}, \text{ for }0<\lambda<1\text{ with }\overline{x} = \lambda x^1 + (1-\lambda)x^2,
	\]
	we will have
	\[
		\overline{x}_{\eta} = \underbrace{\vphantom{x^1_{\eta}}\lambda}_{>0}\underbrace{x^1_{\eta}}_{>0} + \underbrace{\vphantom{x^1_{\eta}}(1-\lambda)}_{>0}\underbrace{x^2_{\eta}}_{\geq 0} \implies x^1_{\eta} = x^2_{\eta} = 0 \implies x^1_{\beta} = x^2_{\beta} = A^{-1}_{\beta}b.
	\]
	Hence, we see that \(\overline{x} = x^1 = x^2\)\conta
\end{proof}

The converse is also true, but it's harder to show.
\begin{theorem}\label{thm:lec5-2}
	If \(\hat{x}\) is an \hyperref[def:extreme-point]{extreme point} of the \hyperref[def:feasible-region]{feasible region} of \((\mathrm{P})\), then \(\hat{x}\) is
	\hyperref[def:basic-solution]{basic}.
\end{theorem}

The proof of this \autoref{thm:lec5-2} is left as an exercise.